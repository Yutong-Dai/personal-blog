





@article{doi:10.1137/21M1411111,
author = {Curtis, Frank E. and Dai, Yutong and Robinson, Daniel P.},
title = {A Subspace Acceleration Method for Minimization Involving a Group Sparsity-Inducing Regularizer},
journal = {SIAM Journal on Optimization},
volume = {32},
number = {2},
pages = {545-572},
year = {2022},
doi = {10.1137/21M1411111},

URL = { 
        https://doi.org/10.1137/21M1411111
    
},
eprint = { 
        https://doi.org/10.1137/21M1411111
    
}
,
    abstract = { We consider the problem of minimizing an objective function that is the sum of a convex function and a group sparsity-inducing regularizer. Problems that integrate such regularizers arise in modern machine learning applications, often for the purpose of obtaining models that are easier to interpret and that have higher predictive accuracy. We present a new method for solving such problems that utilizes subspace acceleration, domain decomposition, and support identification. Our analysis provides the global iteration complexity of obtaining an \$\epsilon\$-accurate solution and shows that, under common assumptions, the iterates locally converge superlinearly. Numerical results on regularized logistic and linear regression problems show that our approach is efficient and reliable and outperforms state-of-the-art methods on interesting classes of problems, especially when the number of data points is larger than the number of features. For solving problems when the number of data points is smaller than the number of features, algorithms that focus on solving a dual problem may be more efficient than our approach, which solves the primal problem. }
}


