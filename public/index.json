[{"authors":["admin"],"categories":null,"content":"Yutong is a Ph.D. student in the Department of Industrial and Systems Engineering at Lehigh University, working under the supervision of Professor Daniel P. Robinson.\nHis current research focus on designing and analyzing algorithms for large scale convex non-smooth optimization problems arisen in machine learning.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1596081872,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"Yutong is a Ph.D. student in the Department of Industrial and Systems Engineering at Lehigh University, working under the supervision of Professor Daniel P. Robinson.\nHis current research focus on designing and analyzing algorithms for large scale convex non-smooth optimization problems arisen in machine learning.","tags":null,"title":"","type":"authors"},{"authors":null,"categories":null,"content":"","date":1597104000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1598900989,"objectID":"47b7058404de98b2b76688e87a07799a","permalink":"/resources/cpp_laopt/cpp/","publishdate":"2020-08-11T00:00:00Z","relpermalink":"/resources/cpp_laopt/cpp/","section":"resources","summary":"","tags":null,"title":"Elements of C++","type":"docs"},{"authors":null,"categories":null,"content":"Demo   Install You can obtain all source code from my github repo.\nUsage Put standalone.tex and note.cls in the same folder and complie.\nMinimal Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  % in your .tex file \\documentclass[doctype=s]{note} \\title{Put your note title here.} \\author{Yutong Dai} \\date{Last Update: \\today} \\usepackage{lipsum} \\usepackage[margin=1.5cm, portrait]{geometry} \\begin{document} % \\maketitle \\pre{Questions} { \\begin{enumerate} \\item{What\u0026#39;s the first question this section will answer?} \\item{What\u0026#39;s the second question?} \\end{enumerate} } \\note[key term 1] { \\begin{itemize} \\item{A cool thing} \\item{Another cool thing} \\item{Not all things are cool} \\end{itemize} } \\note[key term 2] { \\lipsum[4] } \\note[Very very very very very very very very long head] { \\lipsum[5] } \\summary{Summary}{A fabulous summary} \\end{document}   Key components   \\title{}: the title for your document. If you want to leave it blank, please use \\title{}; otherwise use \\title{your title}.\n  \\author{}: the author for your document. If you want to leave it blank, please use \\author{}; otherwise use \\author{your name}.\n  \\date{}: the last modified date for your document. If you want to leave it blank, please use \\date{}; otherwise use \\date{Last Update: \\today}.\n  \\pre{}{}: a pre read block. The first argument is the title for this block and the second argument fills in the block.\n  \\note{}{} a note bolck. The first argument records the keyword and the second argument fills the note content.\n  \\summary{}{}: a summary block. see \\pre{}{}.\n  Modes Two modes are provided for this template,\n  standalone mode[default]: renders the file as a stand-alone file, the one showed in demo. In this mode, when providing title/author/date, please do not use \\maketitle command. These information will be automatically rendered.\n  collection mode: Use this note as a widget, which can be direcrly incorporated in your article. Since note class directly inherit from the article class. To use collection mode just pass doctype=c to the \\documnetclass as the demo code indicates.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  % in your .tex file  \\documentclass[doctype=c]{note} \\title{Put your note title here.} \\author{Yutong Dai} \\date{Last Update: \\today} \\usepackage{lipsum} \\usepackage[margin=1.5cm, portrait]{geometry} \\begin{document} \\maketitle \\tableofcontents \\newpage \\section{First section} \\pre{Questions} { \\begin{enumerate} \\item{What\u0026#39;s the first question this section will answer?} \\item{What\u0026#39;s the second question?} \\end{enumerate} } \\note[key term 1] { \\begin{itemize} \\item{A cool thing} \\item{Another cool thing} \\item{Not all things are cool} \\end{itemize} } \\note[key term 2] { \\lipsum[4] } \\note[Very very very very very very very very long head] { \\lipsum[5] } \\summary{Summary}{A fabulous summary}     Change the layout The default layout is portrait, if you would like to switch to landscape, just use \\usepackage[landscape]{geometry}.\n","date":1596672000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1596741242,"objectID":"15ae87a17a0711f27b24a2181f6f2aa6","permalink":"/resources/tex-rmd/cornellnotes/","publishdate":"2020-08-06T00:00:00Z","relpermalink":"/resources/tex-rmd/cornellnotes/","section":"resources","summary":"Demo   Install You can obtain all source code from my github repo.\nUsage Put standalone.tex and note.cls in the same folder and complie.\nMinimal Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  % in your .","tags":null,"title":"Cornell Notes Template","type":"docs"},{"authors":null,"categories":null,"content":"This page collects $\\LaTeX$ and Rmarkdown templates that I adapted from the Internet for a variety purpose, which includes but not limited to taking lecture notes, writing homework and making cheatsheet.\n","date":1559260800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1596741242,"objectID":"395e2dc8a7bcb516f8e25f58c11ce4cc","permalink":"/resources/tex-rmd/","publishdate":"2019-05-31T00:00:00Z","relpermalink":"/resources/tex-rmd/","section":"resources","summary":"Templates for lecture notes, homework and cheatsheet and more.","tags":null,"title":"Description","type":"docs"},{"authors":null,"categories":null,"content":"","date":1559257200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1596741242,"objectID":"044a932d5db50d3527ec08f5493765e8","permalink":"/resources/tex-rmd/cheatsheet/","publishdate":"2019-05-31T00:00:00+01:00","relpermalink":"/resources/tex-rmd/cheatsheet/","section":"resources","summary":"","tags":null,"title":"Cheatsheet Template","type":"docs"},{"authors":null,"categories":null,"content":"","date":1559257200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1596741242,"objectID":"2eb6399da15e15c42f14efd1d6630dc3","permalink":"/resources/tex-rmd/homework/","publishdate":"2019-05-31T00:00:00+01:00","relpermalink":"/resources/tex-rmd/homework/","section":"resources","summary":"","tags":null,"title":"Homework Template","type":"docs"},{"authors":null,"categories":null,"content":"","date":1559257200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1596741242,"objectID":"d0df433092b6fbcfd8ff37bc345bb505","permalink":"/resources/tex-rmd/lecturenotes/","publishdate":"2019-05-31T00:00:00+01:00","relpermalink":"/resources/tex-rmd/lecturenotes/","section":"resources","summary":"","tags":null,"title":"Lecture Notes Template","type":"docs"},{"authors":null,"categories":null,"content":"416. 分割等和子集 给定一个只包含正整数的非空数组。是否可以将这个数组分割成两个子集，使得两个子集的元素和相等。 注意: 每个数组中的元素不会超过 100 数组的大小不会超过 200 示例 1: 输入: [1, 5, 11, 5] 输出: true 解释: 数组可以分割成 [1, 5, 5] 和 [11]. 示例 2: 输入: [1, 2, 3, 5] 输出: false 解释: 数组不能分割成两个元素和相等的子集. 思路  对edge cases 做判断：如果数组求和为奇数，则肯定不可能。如果为偶数，则将和的一半记为target。 问题转换成是否能从nums选出至少一个元素使得选出的元素和为target。 这个问题可以变成0-1背包为题: 从 nums 中选出物品，其中第i个物品的 cost和value都是nums[i], capacity为target。  关于0-1背包问题的描述和求解可以参考这个 文档.\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  import math class Solution(object): def canPartition(self, nums): \u0026#34;\u0026#34;\u0026#34; :type nums: List[int] :rtype: bool \u0026#34;\u0026#34;\u0026#34; def knapsack(capacity, values): n = len(values) dp = [0 for v in range(capacity+1)] for i in range(1, n+1): for v in range(capacity, values[i-1]-1, -1): dp[v] = max(dp[v], dp[v-values[i-1]]+values[i-1]) return dp[capacity] == capacity total = sum(nums) target = total // 2 if (total - target * 2) != 0: return False return knapsack(target, nums)   复杂度 n=len(nums), V = sum(nums)//2\n 时间复杂度：$O(nV)$ 空间复杂度：$O(V)$  494. 目标和 给定一个非负整数数组，a1, a2, ..., an, 和一个目标数，S。现在你有两个符号 + 和 -。 对于数组中的任意一个整数，你都可以从 + 或 -中选择一个符号添加在前面。 返回可以使最终数组和为目标数 S 的所有添加符号的方法数。 示例： 输入：nums: [1, 1, 1, 1, 1], S: 3 输出：5 解释： -1+1+1+1+1 = 3 +1-1+1+1+1 = 3 +1+1-1+1+1 = 3 +1+1+1-1+1 = 3 +1+1+1+1-1 = 3 一共有5种方法让最终目标和为3。 提示： 数组非空，且长度不会超过 20 。 初始的数组的和不会超过 1000 。 保证返回的最终结果能被 32 位整数存下。 思路 暴力法： 和寻找所有可能的子集一个套路。列举所有可能的子集，该子集里添加+，该子集的补集使用-。不出意外，超时了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  class Solution(object): def findTargetSumWays(self, nums, S): \u0026#34;\u0026#34;\u0026#34; :type nums: List[int] :type S: int :rtype: int \u0026#34;\u0026#34;\u0026#34; n = len(nums) candicates = 1 \u0026lt;\u0026lt; n ans = 0 for c in range(candicates): temp = 0 for rightShift in range(n): if c \u0026gt;\u0026gt; rightShift \u0026amp; 1: temp += nums[rightShift] else: temp -= nums[rightShift] if temp == S: ans += 1 return ans   因为这里每个元素都要选，如何将其转化成背包问题呢。 稍微做下分析。\n 假设nums中所有元素的和为 totalSum。假设添加正号的元素和为P, 添加负号的元素和为N。不难发现 P-N=totalSum 以及 P+N = S。 于是问题变成从 nums选物品使得和刚好为(totalSum + S )/2。 排除一些边界情况(totalSum + S )为奇数, totalSum\u0026lt;S。 dp[i,j]表示 从前i 个元素中选和为j有多少种不同的选法。 dp[0,0]初始为0。 迭代关系为 dp[i,j]=dp[i-1,j] + dp[i-1, j-num[i]]。 对空间进行优化，用一维数组实现上述功能即可。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  class Solution(object): def findTargetSumWays(self, nums, S): \u0026#34;\u0026#34;\u0026#34; :type nums: List[int] :type S: int :rtype: int \u0026#34;\u0026#34;\u0026#34; totalSum = sum(nums) if S \u0026gt; totalSum: return 0 target = (S + totalSum) \u0026gt;\u0026gt; 1 if (S+totalSum) % 2 != 0: return 0 # dp[j]: 和为j 的选法数量 dp = [0] * (target + 1) dp[0] = 1 for i in range(len(nums)): for j in range(target, nums[i] - 1, -1): dp[j] += dp[j-nums[i]] return dp[-1]   复杂度 V = sum(nums), n = len(nums)\n 时间：$O(n*V)$ 空间：$O(V)$  322. 零钱兑换 给定不同面额的硬币 coins 和一个总金额 amount。编写一个函数来计算可以凑成总金额所需的最少的硬币个数。如果没有任何一种硬币组合能组成总金额，返回 -1。 你可以认为每种硬币的数量是无限的。 示例 1： 输入：coins = [1, 2, 5], amount = 11 输出：3 解释：11 = 5 + 5 + 1 示例 2： 输入：coins = [2], amount = 3 输出：-1 示例 3： 输入：coins = [1], amount = 0 输出：0 示例 4： 输入：coins = [1], amount = 1 输出：1 示例 5： 输入：coins = [1], amount = 2 输出：2 提示： 1 \u0026lt;= coins.length \u0026lt;= 12 1 \u0026lt;= coins[i] \u0026lt;= 231 - 1 0 \u0026lt;= amount \u0026lt;= 104 思路 因为是无限银币，可以强行将coins 数列中每个元素重复。其中coins[i] 的重复次数为 amount // coins[i]。 可惜，超时了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  import numpy as np class Solution(object): def coinChange(self, coins, amount): \u0026#34;\u0026#34;\u0026#34; :type coins: List[int] :type amount: int :rtype: int \u0026#34;\u0026#34;\u0026#34; pool = [] for i in coins: pool += [i] * (amount // i) dp = [ np.inf ] * (amount + 1) dp[0] = 0 for i in range(len(pool)): for j in range(amount, pool[i]-1, -1): dp[j] = min(dp[j], dp[j-pool[i]] + 1) if dp[amount] == np.inf: return -1 return dp[amount]   利用动态规划的思想。\n dp[v] 为 要凑够和为 v 最少需要硬币的数量。 递推关系 dp[v] = min {dp[v-coin[i]} 初始化 dp[0] = infty 不难发现 v-coin[i]可以为负数，这时候只需要假设dp[v-coin[i] 为 -infty  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  import numpy as np class Solution(object): def coinChange(self, coins, amount): \u0026#34;\u0026#34;\u0026#34; :type coins: List[int] :type amount: int :rtype: int \u0026#34;\u0026#34;\u0026#34; dp = [ np.inf ] * (amount + 1) dp[0] = 0 maxCoinValue = max(coins) numDifferentCoins = len(coins) for v in range(1, amount+1): temp = np.inf for i in range(numDifferentCoins): if v-coins[i] \u0026lt; 0: continue if dp[v-coins[i]] \u0026lt; temp: temp = dp[v-coins[i]] dp[v] = temp + 1 if dp[amount] == np.inf: return -1 return dp[amount]   复杂度分析  时间复杂度：O(amount*n) 空间复杂度：O(amount)  ","date":1611100800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1611100800,"objectID":"c69086b83b6e05520d5de04718f4e518","permalink":"/resources/dsal/knapsack/","publishdate":"2021-01-20T00:00:00Z","relpermalink":"/resources/dsal/knapsack/","section":"resources","summary":"416. 分割等和子集 给定一个只包含正整数的非空数组。是否可以将这个","tags":null,"title":"背包问题","type":"docs"},{"authors":null,"categories":null,"content":"162. 寻找峰值 题目 峰值元素是指其值大于左右相邻值的元素。 给定一个输入数组 nums，其中 nums[i] ≠ nums[i+1]，找到峰值元素并返回其索引。 数组可能包含多个峰值，在这种情况下，返回任何一个峰值所在位置即可。 你可以假设 nums[-1] = nums[n] = -∞。 示例 1: 输入: nums = [1,2,3,1] 输出: 2 解释: 3 是峰值元素，你的函数应该返回其索引 2。 示例 2: 输入: nums = [1,2,1,3,5,6,4] 输出: 1 或 5 解释: 你的函数可以返回索引 1，其峰值元素为 2； 或者返回索引 5， 其峰值元素为 6。 说明: 你的解法应该是 O(logN) 时间复杂度的。 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/find-peak-element 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路 题目要求是 O(logN) 时间复杂度自然就只有二分了。注意到题目的假设  nums[-1] = nums[n] = -∞，因此即使是单调增／减的序列，峰值也是一定存在的。\n既然使用二分法，自然还是套路的不停地跟新left, right以及mid。关键在于，当 nums 不是有序的情况下，如何每次排除一半的数据？下面就分三种情况讨论。\n  nums是单调增。比较nums[mid]和nums[mid+1]。因为nums是单调增，因此nums[mid]\u0026lt;nums[mid+1]。这表明了nums[mid]一定不可能是峰值。于是搜索区间可以变成[mid+1, right]。 重复操作，我们知道搜索一定会在nums最后一个数停止。\n  nums是单调减。比较nums[mid]和nums[mid+1]。因为nums是单调减，因此nums[mid]\u0026gt;nums[mid+1]。这表明了nums[mid+1]一定不可能是峰值。于是搜索区间可以变成[left, mid]。 重复操作，我们知道搜索一定会在nums第一个数停止。注意比较此处的搜索区间是 [left, mid] 不同于 单调增时的 [mid+1, right]， 原因在于我们不能排除nums[mid]为峰值的可能性(当我们不知道nums是单调减的)。\n  nums不是单调的。这个时候就是把1和2的思路结合一下。先找到mid比较下nums[mid]和nums[mid+1]。如果nums[mid]\u0026lt;nums[mid+1]，则搜索区间可以变成[mid+1, right]；如果 nums[mid]\u0026gt;nums[mid+1]，则搜索区间是 [left, mid]。\n  代码 1 2 3 4 5 6 7 8 9 10 11 12 13  class Solution: def findPeakElement(self, nums: List[int]) -\u0026gt; int: n = len(nums) if n == 0: return 0 left, right = 0, n - 1 while left \u0026lt; right: mid = (left + right) \u0026gt;\u0026gt; 1 if nums[mid] \u0026lt; nums[mid + 1]: left = mid + 1 else: right = mid return left   复杂度  时间：$O(\\log_2 n)$ 空间：$O(1)$  5643 将数组分成三个子数组的方案数 题目 我们称一个分割整数数组的方案是 好的 ，当它满足： 数组被分成三个 非空 连续子数组，从左至右分别命名为 left ， mid ， right 。 left 中元素和小于等于 mid 中元素和，mid 中元素和小于等于 right 中元素和。 给你一个 非负 整数数组 nums ，请你返回 好的 分割 nums 方案数目。由于答案可能会很大，请你将结果对 109 + 7 取余后返回。 示例 1： 输入：nums = [1,1,1] 输出：1 解释：唯一一种好的分割方案是将 nums 分成 [1] [1] [1] 。 示例 2： 输入：nums = [1,2,2,2,5,0] 输出：3 解释：nums 总共有 3 种好的分割方案： [1] [2] [2,2,5,0] [1] [2,2] [2,5,0] [1,2] [2,2] [5,0] 示例 3： 输入：nums = [3,2,1] 输出：0 解释：没有好的分割方案。 提示： 3 \u0026lt;= nums.length \u0026lt;= 10^5 0 \u0026lt;= nums[i] \u0026lt;= 10^4 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/ways-to-split-array-into-three-subarrays 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路 前缀和 + 二分法。\n 首先说为何想到要用前缀和？  如果给定一个划分，我们如何判断它是不是一个好的划分？我们只需要把left, mid， right 中的元素全部加起来，然后比较大小即可。 为了避免重复的加法，我们想到了前缀和。具体来说，只要给定了一种划分（划分用索引的形式的表达，cut1和cut2, 表示分别在nums[cut1] nums[cut2]处截断）， 我们便知道了left=sum(nums[0 : cut1] (包含cut1), mid=sum(nums[cut1+1:cut2])， right=sum(nums[cut2+1:n])。 接下来只需要用一个双循环去遍历所有可能的cut1和cut2，我们便可以找到所有好的划分。最后利用一些剪枝的技巧， 当sum(nums[cut1+1:cut2]) \u0026gt; sum(nums[cut2+1:end])时我们可以终止内层循环。代码如下。    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  class Solution: def waysToSplit(self, nums: List[int]) -\u0026gt; int: n = len(nums) if n \u0026lt; 3: return 0 ans = 0 # get cumulative sum for i in range(1, len(nums)): nums[i] += nums[i-1] last = n - 1 for first in range(n-2): for second in range(first+1, n-1): cumsum_mid = nums[second] - nums[first] cumsum_right = nums[last] - nums[second] if cumsum_mid \u0026gt;= nums[first] and cumsum_right \u0026gt;= cumsum_mid: ans += 1 # prune if cumsum_right \u0026lt; cumsum_mid: break return ans % (1000000007)   为何使用二分法?  上述算法的时间复杂度为$O(n^2)$, 而数据量len(nums)=1e5。根据lucifer的复杂度表，我们需要一个$O(n\\log_2n)$的算法。 优化什么？ 如果我们可以把内层循环变成一个$O(\\log_2 n)$的算法，那就大功告成。我们内层循环本质是, 当给定cut1的时候, 寻找第二个截断cut2使得 sum(nums[0 : cut1] \u0026lt;= sum(nums[cut1+1:cut2]) \u0026lt;= sum(nums[cut2+1:n])。 怎么优化？用二分法来进行优化。首先构造一个cumsum来表示nums的前缀和。其中cum[i]=sum(nums[:i])。注意到 cumsum是单调不减的 (意味着nums可能有重复的元素!!)， 因此我们需要找到 最左边的cut2 和 最右边的cut2, 即找到 [cut1+1, n-1)中最小和最大的元素使得sum(nums[0 : cut1] \u0026lt;= sum(nums[cut1+1:cut2]) \u0026lt;= sum(nums[cut2+1:end])成立。 (注意是左开右闭，我也是提交后错了才意识到。因为cut2 不能在最后一个元素处，否则right是一个空数组。考虑[0,0,0,0]这样输入。) （再加点细节）比如我们要找到最右边的cut2。我们则需要从 [cut1+1, n-1]中寻找最大满足条件的值。假设l, r, mid为二分搜索时的三个指针。我们可以定义cumsum_left = cumsum[cut1], cumsum_mid = cumsum[mid] - cumsum_left, cumsum_right=cumsum[n] - cumsum_mid。然后有如下四种情况进行讨论    cumsum_mid \u0026gt;= cumsum_left and cumsum_right \u0026gt;= cumsum_mid 此时我们找到一个合格的cut2，作为备选。并将 l 指向 mid+1,来寻找潜在更大的cut2 cumsum_mid \u0026lt; cumsum_left and cumsum_right \u0026gt;= cumsum_mid 此时的cut2太小了，我们需要增加 l 到 mid + 1，来获得更大的 cumsum_mid cumsum_mid \u0026gt;= cumsum_left and cumsum_right \u0026lt; cumsum_mid 此时的cut2太大了，我们需要减小 r 到 mid - 1，来获得更大的 cumsum_right cumsum_mid \u0026lt; cumsum_left and cumsum_right \u0026lt; cumsum_mid 不存在可行的cut2，直接剪枝了。因为此时需要同时增大cumsum_mid 和 cumsum_right 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  class Solution: def waysToSplit(self, nums: List[int]) -\u0026gt; int: self.n = len(nums) if self.n \u0026lt; 3: return 0 ans = 0 # get cumulative sum for i in range(1, self.n): nums[i] += nums[i-1] self.cumsum = nums for left in range(self.n-2): cumsum_left = nums[left] if cumsum_left * 3 \u0026gt; self.cumsum[-1]: break rightMostCut = self.right_find(left+1, cumsum_left) leftMostCut = self.left_find(left+1, cumsum_left) if rightMostCut != -1: ans += rightMostCut - leftMostCut + 1 return ans % (1000000007) def right_find(self, start, cumsum_left): l, r = start, self.n - 1 ans = -1 while l \u0026lt;= r: mid = (l+r) \u0026gt;\u0026gt; 1 cumsum_mid = self.cumsum[mid] - cumsum_left cumsum_right = self.cumsum[-1] - self.cumsum[mid] # find a qualified cut if cumsum_mid \u0026gt;= cumsum_left and cumsum_right \u0026gt;= cumsum_mid: l = mid + 1 ans = mid # need to increase the cumsum_mid elif cumsum_mid \u0026lt; cumsum_left and cumsum_right \u0026gt;= cumsum_mid: l = mid + 1 # need to decrease the cumsum_mid elif cumsum_mid \u0026gt;= cumsum_left and cumsum_right \u0026lt; cumsum_mid: r = mid - 1 # no answer else: break return min(ans, self.n-2) def left_find(self, start, cumsum_left): l, r = start, self.n - 1 ans = -1 while l \u0026lt;= r: mid = (l+r) \u0026gt;\u0026gt; 1 cumsum_mid = self.cumsum[mid] - cumsum_left cumsum_right = self.cumsum[-1] - self.cumsum[mid] # find a qualified cut if cumsum_mid \u0026gt;= cumsum_left and cumsum_right \u0026gt;= cumsum_mid: r = mid - 1 ans = mid # need to increase the cumsum_mid elif cumsum_mid \u0026lt; cumsum_left and cumsum_right \u0026gt;= cumsum_mid: l = mid + 1 # need to decrease the cumsum_mid elif cumsum_mid \u0026gt;= cumsum_left and cumsum_right \u0026lt; cumsum_mid: r = mid - 1 # no answer else: break return ans   复杂度  时间复杂度：$O(n\\log_2n)$ 空间复杂度：$O(n)$  4. 寻找两个正序数组的中位数 给定两个大小为 m 和 n 的正序（从小到大）数组 nums1 和 nums2。请你找出并返回这两个正序数组的中位数。 进阶：你能设计一个时间复杂度为 O(log (m+n)) 的算法解决此问题吗？ 示例 1： 输入：nums1 = [1,3], nums2 = [2] 输出：2.00000 解释：合并数组 = [1,2,3] ，中位数 2 示例 2： 输入：nums1 = [1,2], nums2 = [3,4] 输出：2.50000 解释：合并数组 = [1,2,3,4] ，中位数 (2 + 3) / 2 = 2.5 示例 3： 输入：nums1 = [0,0], nums2 = [0,0] 输出：0.00000 示例 4： 输入：nums1 = [], nums2 = [1] 输出：1.00000 示例 5： 输入：nums1 = [2], nums2 = [] 输出：2.00000 提示： nums1.length == m nums2.length == n 0 \u0026lt;= m \u0026lt;= 1000 0 \u0026lt;= n \u0026lt;= 1000 1 \u0026lt;= m + n \u0026lt;= 2000 -106 \u0026lt;= nums1[i], nums2[i] \u0026lt;= 106 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/median-of-two-sorted-arrays 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路 我是看这里的 方法三.\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  class Solution: def findMedianSortedArrays(self, nums1: List[int], nums2: List[int]) -\u0026gt; float: m = len(nums1) n = len(nums2) # 对m+n的奇偶分开讨论； # m+n 为奇数时 median_idx_odd 和 median_idx_even 一样 # m+n 为偶数时 median_idx_odd 比 median_idx_even 小1 median_idx_odd = (m + n - 1) \u0026gt;\u0026gt; 1 median_idx_even = (m + n) \u0026gt;\u0026gt; 1 if median_idx_even == median_idx_odd: return self.findKthSmallet(nums1, 0, m-1, nums2, 0, n-1, median_idx_odd+1) else: return (self.findKthSmallet(nums1, 0, m-1, nums2, 0, n-1, median_idx_odd+1) + self.findKthSmallet(nums1, 0, m-1, nums2, 0, n-1, median_idx_even+1)) / 2 def findKthSmallet(self, nums1, start1, end1, nums2, start2, end2, k): m = end1 - start1 + 1 n = end2 - start2 + 1 # nums1 中的元素被用完了 if m == 0: return nums2[start2+k-1] # nums2 中的元素被用完了 if n == 0: return nums1[start1+k-1] # 只需要找最后一个 if k == 1: return min(nums1[start1], nums2[start2]) idx1 = start1 + min(k\u0026gt;\u0026gt;1, m) - 1 idx2 = start2 + min(k\u0026gt;\u0026gt;1, n) - 1 if nums1[idx1] \u0026gt; nums2[idx2]: newk = k - (idx2-start2+1) return self.findKthSmallet(nums1, start1, end1, nums2, idx2+1, end2, newk) else: newk = k - (idx1-start1+1) return self.findKthSmallet(nums1, idx1+1, end1, nums2, start2, end2, newk)   复杂度  时间: $O(\\log_2(m+n))$ 空间: $O(1)$ (使用尾递归， 但是python 没有尾递归优化，所以是 $O(\\log_2(m+n))$)  ","date":1609632000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1610906548,"objectID":"39ca4d463f40dbb174af994e7e02becc","permalink":"/resources/dsal/bisection/","publishdate":"2021-01-03T00:00:00Z","relpermalink":"/resources/dsal/bisection/","section":"resources","summary":"162. 寻找峰值 题目 峰值元素是指其值大于左右相邻值的元素。 给定一个","tags":null,"title":"二分法","type":"docs"},{"authors":null,"categories":null,"content":"435. 无重叠区间 给定一个区间的集合，找到需要移除区间的最小数量，使剩余区间互不重叠。 注意: 可以认为区间的终点总是大于它的起点。 区间 [1,2] 和 [2,3] 的边界相互“接触”，但没有相互重叠。 示例 1: 输入: [ [1,2], [2,3], [3,4], [1,3] ] 输出: 1 解释: 移除 [1,3] 后，剩下的区间没有重叠。 示例 2: 输入: [ [1,2], [1,2], [1,2] ] 输出: 2 解释: 你需要移除两个 [1,2] 来使剩下的区间没有重叠。 示例 3: 输入: [ [1,2], [2,3] ] 输出: 0 解释: 你不需要移除任何区间，因为它们已经是无重叠的了。 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/non-overlapping-intervals 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路 考虑如下一组输入\n[[1, 100], [11, 22], [1, 11], [2, 12]] 最长无重叠的区间是\nnonOverlap = [[1, 11], [11, 22]] 或者 nonOverlap = [[2, 12], [11, 22]] 一个重要的观察: nonOverlap[i][1] \u0026lt;= nonOverlap[i+1][0], 即两个相邻的区间，前一个区间的右端点小于等于后一个区间的左端点。所以先考虑对输入的intervals中的区间按照右端点的大小进行升序排列。\n接下来构建动态规划的叠加公式，我们有两种选择。下面考虑第一种\n选项一: dp[i]表示 intervals[0], ... , intervals[i]中含有 intervals[i]最长不重叠区间。该情况下的迭代公式为\n$$ dp[i] = \\max_{0\\leq j \\leq i-1}(dp[j]) + 1 \\qquad \\text{s.t. } dp[i][0] \u0026gt;= dp[j][1] $$\n代码\n1 2 3 4 5 6 7 8 9 10 11 12 13  class Solution: def eraseOverlapIntervals(self, intervals: List[List[int]]) -\u0026gt; int: if not intervals or len(intervals) == 1: return 0 # sort by the ending time intervals = sorted(intervals, key=lambda t: t[1]) n = len(intervals) dp = [1] * n for i in range(1, n): for j in range(i): if intervals[j][1] \u0026lt;= intervals[i][0]: dp[i] = max(dp[i], dp[j] + 1) return n - max(dp)   这种做法不能通过，会超时。我们可不可优化一下呢？ 下面考虑第二种选项。\n选项二: dp[i]表示 intervals[0], ... , intervals[i]中最长不重叠区间(即不一定含有intervals[i])。这种定义的好处可以保证dp是一个单调不减的序列。 该情况下的迭代公式为\n$$ dp[i] = dp[j_*] + 1 \\qquad \\text{s.t. } j_*=\\arg\\max{(j| dp[i][0] \u0026gt;= dp[j][1], 0\\leq j \\leq i-1)}. $$\n这个迭代公式的好处在于,可以提前剪枝（虽然没有改变时间复杂度）。\n代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  class Solution: def eraseOverlapIntervals(self, intervals: List[List[int]]) -\u0026gt; int: if not intervals or len(intervals) == 1: return 0 # sort by the ending time intervals = sorted(intervals, key=lambda t: t[1]) n = len(intervals) dp = [1] * n for i in range(1, n): for j in range(i-1, -1, -1): if intervals[j][1] \u0026lt;= intervals[i][0]: dp[i] = max(dp[i], dp[j] + 1) # 提前剪枝 break dp[i] = max(dp[i], dp[i-1]) return n - max(dp)   复杂度:\n 时间: $O(n^2)$ 空间: $O(n)$  837. 新21点 爱丽丝参与一个大致基于纸牌游戏 “21点” 规则的游戏，描述如下： 爱丽丝以 0 分开始，并在她的得分少于 K 分时抽取数字。 抽取时，她从 [1, W] 的范围中随机获得一个整数作为分数进行累计，其中 W 是整数。 每次抽取都是独立的，其结果具有相同的概率。 当爱丽丝获得不少于 K 分时，她就停止抽取数字。 爱丽丝的分数不超过 N 的概率是多少？ 示例 1： 输入：N = 10, K = 1, W = 10 输出：1.00000 说明：爱丽丝得到一张卡，然后停止。 示例 2： 输入：N = 6, K = 1, W = 10 输出：0.60000 说明：爱丽丝得到一张卡，然后停止。 在 W = 10 的 6 种可能下，她的得分不超过 N = 6 分。 示例 3： 输入：N = 21, K = 17, W = 10 输出：0.73278 提示： 0 \u0026lt;= K \u0026lt;= N \u0026lt;= 10000 1 \u0026lt;= W \u0026lt;= 10000 如果答案与正确答案的误差不超过 10^-5，则该答案将被视为正确答案通过。 此问题的判断限制时间已经减少。 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/new-21-game 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路 参考 这里.\n代码 1 2 3 4 5 6 7 8 9 10  class Solution: def new21Game(self, N: int, K: int, W: int) -\u0026gt; float: if K == 0: return 1 dp = [0] * ((K-1+W) + 1) for j in range(K, min(N, K-1+W)+1): dp[j] = 1 dp[K-1] = min(N-K+1, W) / W for s in range(K-1, 0, -1): dp[s-1] = dp[s] + (dp[s] - dp[s+W]) / W return dp[0]   复杂度  时间复杂度: $O(K+W)$ 空间复杂度: $O(K+W)$  438. 找到字符串中所有字母异位词 给定一个字符串 s 和一个非空字符串 p，找到 s 中所有是 p 的字母异位词的子串，返回这些子串的起始索引。 字符串只包含小写英文字母，并且字符串 s 和 p 的长度都不超过 20100。 说明： 字母异位词指字母相同，但排列不同的字符串。 不考虑答案输出的顺序。 示例 1: 输入: s: \u0026quot;cbaebabacd\u0026quot; p: \u0026quot;abc\u0026quot; 输出: [0, 6] 解释: 起始索引等于 0 的子串是 \u0026quot;cba\u0026quot;, 它是 \u0026quot;abc\u0026quot; 的字母异位词。 起始索引等于 6 的子串是 \u0026quot;bac\u0026quot;, 它是 \u0026quot;abc\u0026quot; 的字母异位词。 示例 2: 输入: s: \u0026quot;abab\u0026quot; p: \u0026quot;ab\u0026quot; 输出: [0, 1, 2] 解释: 起始索引等于 0 的子串是 \u0026quot;ab\u0026quot;, 它是 \u0026quot;ab\u0026quot; 的字母异位词。 起始索引等于 1 的子串是 \u0026quot;ba\u0026quot;, 它是 \u0026quot;ab\u0026quot; 的字母异位词。 起始索引等于 2 的子串是 \u0026quot;ab\u0026quot;, 它是 \u0026quot;ab\u0026quot; 的字母异位词。 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/find-all-anagrams-in-a-string 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路 刚开始做想到用一个set来记录p中的字母，然后利用滑动窗口记录当前窗口中元素与set的匹配情况。后来发现测试案例中有 p=‘aa’这种带重复字母的情况。所以变成用一个长度为26的list来记录p中每个元素出现的频率，然后再开一个长度为26的list 来记录s中当前窗口字母的频次，如果两个list一样，则找到一个符合条件的字母异位词。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  class Solution: def findAnagrams(self, s: str, p: str) -\u0026gt; List[int]: n, size = len(s), len(p) ans = [] if n \u0026lt; size: return ans p_array = [0] * 26 s_array = [0] * 26 for i in range(size): p_array[ord(p[i]) - ord(\u0026#39;a\u0026#39;)] += 1 s_array[ord(s[i]) - ord(\u0026#39;a\u0026#39;)] += 1 if s_array == p_array: ans.append(0) l = 0 while l \u0026lt; n-size: l += 1 r = l + size - 1 s_array[ord(s[l-1]) - ord(\u0026#39;a\u0026#39;)] -= 1 s_array[ord(s[r]) - ord(\u0026#39;a\u0026#39;)] += 1 if s_array == p_array: ans.append(l) return ans   复杂度分析  时间复杂度：$O(n)$, n为s的长度; 空间复杂度：$O(1)$  代码的改进 仔细看代码，发现比较两个数组s_array == p_array可以优化。具体来说\n 初始一个 debit的list。遍历p中的字符，并在debit中该字符对应的位置减去1，表示“负债”情况。 每次跟新窗口的时候，如果移除的字母当前对应的debit小于等于0，则说明该字母出现在p中; 对增加的字母也可同理。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  class Solution: def findAnagrams(self, s: str, p: str) -\u0026gt; List[int]: n, size = len(s), len(p) ans = [] if n \u0026lt; size: return ans debit = [0] * 26 for char in p: # 初始负债情况 debit[ord(char) - ord(\u0026#39;a\u0026#39;)] -= 1 l = 0 lack = size for i in range(size): idx = ord(s[i]) - ord(\u0026#39;a\u0026#39;) # 给正确的地方充值 if debit[idx] \u0026lt; 0: lack -= 1 debit[idx] += 1 # 负债为0，当前窗口的字母和p中字母匹配上了 if lack == 0: ans.append(l) while l \u0026lt; n-size: l += 1 r = l + size - 1 rm_idx = ord(s[l-1]) - ord(\u0026#39;a\u0026#39;) add_idx = ord(s[r]) - ord(\u0026#39;a\u0026#39;) # 给正确的地方扣钱 if debit[rm_idx] \u0026lt;= 0: lack += 1 debit[rm_idx] -= 1 debit[add_idx] += 1 # 给正确的地方充值 if debit[add_idx] \u0026lt;= 0: lack -= 1 if lack == 0: ans.append(l) return ans   338. 比特位计数 给定一个非负整数 num。对于 0 ≤ i ≤ num 范围中的每个数字 i ，计算其二进制数中的 1 的数目并将它们作为数组返回。 示例 1: 输入: 2 输出: [0,1,1] 示例 2: 输入: 5 输出: [0,1,1,2,1,2] 进阶: 给出时间复杂度为O(n*sizeof(integer))的解答非常容易。但你可以在线性时间O(n)内用一趟扫描做到吗？ 要求算法的空间复杂度为O(n)。 你能进一步完善解法吗？要求在C++或任何其他语言中不使用任何内置函数（如 C++ 中的 __builtin_popcount）来执行此操作。 思路 动态规划 + 位运算\n dp[i]: 数字i中1的个数 如果i是奇数，则dp[i]=dp[i-1]+1， 因为i的二进制表达中末尾一定是1恰好比dp[i-1]的二进制表达多出1个1 如果i是偶数, 不难发现其二进制表达中末尾一定是0，因此去掉该0对最后结果没有影响。而i\u0026gt;\u0026gt;1一定比i小，而且我们已经计算过了。  代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  class Solution(object): def countBits(self, num): \u0026#34;\u0026#34;\u0026#34; :type num: int :rtype: List[int] \u0026#34;\u0026#34;\u0026#34; if num == 0: return [0] dp = [0] * (num+1) for i in range(1, num+1): if i % 2 == 1: dp[i] = dp[i-1] + 1 if i % 2 == 0: dp[i] = dp[i\u0026gt;\u0026gt;1] return dp   复杂度分析  时间复杂度：O(n) 空间复杂度：不算返回的数组的话应该是 O(1)  ","date":1607904000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1610906548,"objectID":"1da1d39c62a2b0ce4b799da9b834ab6c","permalink":"/resources/dsal/dp/","publishdate":"2020-12-14T00:00:00Z","relpermalink":"/resources/dsal/dp/","section":"resources","summary":"435. 无重叠区间 给定一个区间的集合，找到需要移除区间的最小数量，","tags":null,"title":"动态规划","type":"docs"},{"authors":null,"categories":null,"content":"695. 岛屿的最大面积 给定一个包含了一些 0 和 1 的非空二维数组 grid 。 一个 岛屿 是由一些相邻的 1 (代表土地) 构成的组合，这里的「相邻」要求两个 1 必须在水平或者竖直方向上相邻。你可以假设 grid 的四个边缘都被 0（代表水）包围着。 找到给定的二维数组中最大的岛屿面积。(如果没有岛屿，则返回面积为 0 。) 示例 1: [[0,0,1,0,0,0,0,1,0,0,0,0,0], [0,0,0,0,0,0,0,1,1,1,0,0,0], [0,1,1,0,1,0,0,0,0,0,0,0,0], [0,1,0,0,1,1,0,0,1,0,1,0,0], [0,1,0,0,1,1,0,0,1,1,1,0,0], [0,0,0,0,0,0,0,0,0,0,1,0,0], [0,0,0,0,0,0,0,1,1,1,0,0,0], [0,0,0,0,0,0,0,1,1,0,0,0,0]] 对于上面这个给定矩阵应返回 6。注意答案不应该是 11 ，因为岛屿只能包含水平或垂直的四个方向的 1 。 示例 2: [[0,0,0,0,0,0,0,0]] 对于上面这个给定的矩阵, 返回 0。 注意: 给定的矩阵grid 的长度和宽度都不超过 50。 思路  利用dfs搜索，如果在从(i,j)处开始（假设grid[i][j]=1）寻找最多连通的小岛，为其左，右，上, 下，开始搜索最多连通小岛数之和再加一。 需要防止重复计数。具体做法就是再访问一个点后就永远将其设置为0。考虑下面这个例子，如果访问完一个位置后，将其重置为1，就会重复计数: dfs(0,0)=3+3+1=7错误答案。  代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  class Solution: def maxAreaOfIsland(self, grid: List[List[int]]) -\u0026gt; int: m = len(grid) if m == 0: return 0 n = len(grid[0]) if n == 0: return 0 memory = [[0 for j in n] for i in m] def dfs(i,j): if i\u0026lt;0 or i\u0026gt;=m or j\u0026lt;0 or j\u0026gt;=n: return 0 if grid[i][j] == 0: return 0 grid[i][j] = 0 left = dfs(i, j-1) right = dfs(i, j+1) up = dfs(i-1, j) down = dfs(i+1, j) return 1 + left + right + up + down ans = 0 for i in range(m): for j in range(n): ans = max(ans, dfs(i,j)) return ans   复杂度 时间复杂度：$O(mn)$ 空间复杂度：$O(mn)$ （递归栈深度）\n1162. 地图分析 你现在手里有一份大小为 N x N 的 网格 grid，上面的每个 单元格 都用 0 和 1 标记好了。其中 0 代表海洋，1 代表陆地，请你找出一个海洋单元格，这个海洋单元格到离它最近的陆地单元格的距离是最大的。 我们这里说的距离是「曼哈顿距离」（ Manhattan Distance）：(x0, y0) 和 (x1, y1) 这两个单元格之间的距离是 |x0 - x1| + |y0 - y1| 。 如果网格上只有陆地或者海洋，请返回 -1。 示例 1： 输入：[[1,0,1],[0,0,0],[1,0,1]] 输出：2 解释： 海洋单元格 (1, 1) 和所有陆地单元格之间的距离都达到最大，最大距离为 2。 示例 2： 输入：[[1,0,0],[0,0,0],[0,0,0]] 输出：4 解释： 海洋单元格 (2, 2) 和所有陆地单元格之间的距离都达到最大，最大距离为 4。 提示： 1 \u0026lt;= grid.length == grid[0].length \u0026lt;= 100 grid[i][j] 不是 0 就是 1 思路  不难发现海洋(i, j)离最近陆地的距离依赖于其上下左右邻居的位置。 最开始想到用dfs 来找，然后发现有很多坑。于是考虑用bfs的写法，从(i,j)开始寻找其上下左右邻居是否唯一，类似于二叉树带层数记忆的层次遍历，找到的第一个陆地即为答案，不需要queue为空才退出。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  class Solution(object): def maxDistance(self, grid): m = len(grid) if m == 0: return 0 n = len(grid[0]) if n == 0: return 0 # memory = [[0 for j in range(n)] for i in range(m)] def bfs(i,j): queue = [(i,j,0)] visited = [[0 for j in range(n)] for i in range(m)] while queue: i,j, step = queue.pop(0) visited[i][j] = 1 move = [(0,-1), (0,1), (-1,0), (1,0)] for dxdy in move: newi, newj = i+dxdy[0], j+dxdy[1] if ( (newi\u0026gt;=0) and (newi\u0026lt;m) and (newj\u0026gt;=0) and (newj\u0026lt;n)): if grid[newi][newj] == 1: return step + 1 else: if visited[newi][newj] != 1: queue.append((newi, newj, step+1)) return -1 stepMax = -1 for i in range(m): for j in range(n): if grid[i][j] != 1: stepMax = max(stepMax, bfs(i,j)) return stepMax   可惜这种写法超时了，因为我们会重复遍历很多相同的格子。时间复杂度为 $O(m^2n^2)$。\n看了 题解，感觉十分巧妙，让所有小岛进入queue，然后从小岛开始向周围扩散，能扩散的最远距离即为答案。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  class Solution(object): def maxDistance(self, grid): m = len(grid) if m == 0: return 0 n = len(grid[0]) if n == 0: return 0 queue = [(i, j) for i in range(m) for j in range(n) if grid[i][j] == 1] if len(queue) == 0 or len(queue) == m * n: return -1 step = 0 while queue: move = [(0,-1), (0,1), (-1,0), (1,0)] for _ in range(len(queue)): i,j = queue.pop(0) for dxdy in move: newi, newj = i+dxdy[0], j+dxdy[1] if ( (newi\u0026gt;=0) and (newi\u0026lt;m) and (newj\u0026gt;=0) and (newj\u0026lt;n) and grid[newi][newj] == 0): queue.append((newi, newj)) grid[newi][newj] = 1 step += 1 # 这里小心点，和计数方式有关 return step - 1   复杂度  时间复杂度：$O(n^2)$ 空间复杂度：$O(n^2)$  113. 路径总和 II 给定一个二叉树和一个目标和，找到所有从根节点到叶子节点路径总和等于给定目标和的路径。 说明: 叶子节点是指没有子节点的节点。 示例: 给定如下二叉树，以及目标和 sum = 22， 5 / \\ 4 8 / / \\ 11 13 4 / \\ / \\ 7 2 5 1 返回: [ [5,4,11,2], [5,8,4,5] ] 思路 dfs 遍历整颗树，记住整条路上的所有元素，到叶节点时判断下和是否为要求的值。\n之前还想通过当前从root到当前node 上path之和来剪枝，然后发现居然可以有负值的node 和 负值的sum。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  from copy import deepcopy class Solution(object): def pathSum(self, root, sum): \u0026#34;\u0026#34;\u0026#34; :type root: TreeNode :type sum: int :rtype: List[List[int]] \u0026#34;\u0026#34;\u0026#34; if not root: return [] ans = [] def dfs(node, path, target): path.append(node.val) if node.left == None and node.right == None and target == node.val: ans.append(deepcopy(path)) path.pop(-1) return if node.left == None and node.right == None and target != node.val: path.pop(-1) return if node.left: dfs(node.left, path, target-node.val) if node.right: dfs(node.right, path, target-node.val) path.pop(-1) return dfs(root, [], sum) return ans   复杂度  时间： $O(n)$ 节点数 空间：不算返回的答案的话 $O(\\log_2(n))$ 栈深度  301. 删除无效的括号 删除最小数量的无效括号，使得输入的字符串有效，返回所有可能的结果。 说明: 输入可能包含了除 ( 和 ) 以外的字符。 示例 1: 输入: \u0026quot;()())()\u0026quot; 输出: [\u0026quot;()()()\u0026quot;, \u0026quot;(())()\u0026quot;] 示例 2: 输入: \u0026quot;(a)())()\u0026quot; 输出: [\u0026quot;(a)()()\u0026quot;, \u0026quot;(a())()\u0026quot;] 示例 3: 输入: \u0026quot;)(\u0026quot; 输出: [\u0026quot;\u0026quot;] 思路  参考题解 BFS\n 每次从字符串中删除一个括号字符，并列举出所有可能的结果，用set()存储避免重复情况出现 判断列举出的所有结果是否有有效的字符串，如果有直接返回有效字符串 如果没有有效字符串，说明删除的字符还不够多，再删除一个括号字符，列举出所有可能的结果 继续判断列举出的所有结果中是否有有效字符，如果有直接返回有效字符串 一直循环以上删除一个字符--\u0026gt;判断是否有有效字符串的步骤，直到找到有效字符串为止  代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  class Solution(object): def removeInvalidParentheses(self, s): \u0026#34;\u0026#34;\u0026#34; :type s: str :rtype: List[str] \u0026#34;\u0026#34;\u0026#34; def isValid(string): count = 0 for char in string: if char == \u0026#39;(\u0026#39;: count += 1 if char == \u0026#39;)\u0026#39;: count -= 1 if count \u0026lt; 0: return False if count\u0026gt;0: return False else: return True current_level = {s} while True: ans = filter(isValid, current_level) if ans: return ans next_level = set() for item in current_level: for i in range(len(item)): if item[i] in \u0026#39;()\u0026#39;: next_level.add(item[:i] + item[i+1:]) current_level = next_level   复杂度  时间复杂度：$O(2^n)$ 空间复杂度：$O(n!)$  ","date":1607904000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1610906548,"objectID":"4ea2fb600ba58daf3fccb777c646e613","permalink":"/resources/dsal/search/","publishdate":"2020-12-14T00:00:00Z","relpermalink":"/resources/dsal/search/","section":"resources","summary":"695. 岛屿的最大面积 给定一个包含了一些 0 和 1 的非空二维数组 grid 。 一","tags":null,"title":"搜索算法","type":"docs"},{"authors":null,"categories":null,"content":"1456.定长子串中元音的最大数目 给你字符串 s 和整数 k 。 请返回字符串 s 中长度为 k 的单个子字符串中可能包含的最大元音字母数。 英文中的 元音字母 为（a, e, i, o, u）。 示例 1： 输入：s = \u0026quot;abciiidef\u0026quot;, k = 3 输出：3 解释：子字符串 \u0026quot;iii\u0026quot; 包含 3 个元音字母。 示例 2： 输入：s = \u0026quot;aeiou\u0026quot;, k = 2 输出：2 解释：任意长度为 2 的子字符串都包含 2 个元音字母。 示例 3： 输入：s = \u0026quot;leetcode\u0026quot;, k = 3 输出：2 解释：\u0026quot;lee\u0026quot;、\u0026quot;eet\u0026quot; 和 \u0026quot;ode\u0026quot; 都包含 2 个元音字母。 示例 4： 输入：s = \u0026quot;rhythms\u0026quot;, k = 4 输出：0 解释：字符串 s 中不含任何元音字母。 示例 5： 输入：s = \u0026quot;tryhard\u0026quot;, k = 4 输出：1 提示： 1 \u0026lt;= s.length \u0026lt;= 10^5 s 由小写英文字母组成 1 \u0026lt;= k \u0026lt;= s.length 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/maximum-number-of-vowels-in-a-substring-of-given-length 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路 滑动窗口。\n 首先检查前 k字符里有多少个元音字母。记录为ans 建立 l, r左右指针，每次将l和r增加1，直到越界。同时可以只关心增加的字符(r右移动)和移除的字符(l左移动)是否是元音(用hashTable)便可得到到当前窗口中元音字母个数。最后和ans比较取较大的即可。  代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  class Solution: def maxVowels(self, s: str, k: int) -\u0026gt; int: vowel = set([\u0026#39;a\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;i\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;u\u0026#39;]) r, l = k-1, 0 n = len(s) ans = 0 for i in range(l, r+1): if s[i] in vowel: ans += 1 last_window = ans while r \u0026lt; n: l += 1 r += 1 current_window = last_window if s[l-1] in vowel: current_window -= 1 if r \u0026lt; n and s[r] in vowel: current_window += + 1 ans = max(ans, current_window) last_window = current_window return ans   复杂度  时间复杂度：$O(n)$ 空间复杂度：$O(1)$  1423. 可获得的最大点数 几张卡牌 排成一行，每张卡牌都有一个对应的点数。点数由整数数组 cardPoints 给出。 每次行动，你可以从行的开头或者末尾拿一张卡牌，最终你必须正好拿 k 张卡牌。 你的点数就是你拿到手中的所有卡牌的点数之和。 给你一个整数数组 cardPoints 和整数 k，请你返回可以获得的最大点数。 示例 1： 输入：cardPoints = [1,2,3,4,5,6,1], k = 3 输出：12 解释：第一次行动，不管拿哪张牌，你的点数总是 1 。但是，先拿最右边的卡牌将会最大化你的可获得点数。最优策略是拿右边的三张牌，最终点数为 1 + 6 + 5 = 12 。 示例 2： 输入：cardPoints = [2,2,2], k = 2 输出：4 解释：无论你拿起哪两张卡牌，可获得的点数总是 4 。 示例 3： 输入：cardPoints = [9,7,7,9,7,7,9], k = 7 输出：55 解释：你必须拿起所有卡牌，可以获得的点数为所有卡牌的点数之和。 示例 4： 输入：cardPoints = [1,1000,1], k = 1 输出：1 解释：你无法拿到中间那张卡牌，所以可以获得的最大点数为 1 。 示例 5： 输入：cardPoints = [1,79,80,1,1,1,200,1], k = 3 输出：202 提示： 1 \u0026lt;= cardPoints.length \u0026lt;= 10^5 1 \u0026lt;= cardPoints[i] \u0026lt;= 10^4 1 \u0026lt;= k \u0026lt;= cardPoints.length 思路  假设卡片是首位相连的。 找到一个窗口大小是k的滑动窗口，使得窗口内数字和最大。  为了满足抽卡的规则, 初始化left=0, right=k-1。然后不停将left向左滑动left = n-i， i是滑动的次数。 根据题意，最多可以滑动k 次。\n代码 class Solution: def maxScore(self, cardPoints: List[int], k: int) -\u0026gt; int: n = len(cardPoints) windowSum = 0 for i in range(k): windowSum += cardPoints[i] ans = windowSum for i in range(k): windowSum = windowSum-cardPoints[k-1-i] + cardPoints[n-1-i] ans = max(windowSum, ans) return ans 768. 最多能完成排序的块 II 这个问题和“最多能完成排序的块”相似，但给定数组中的元素可以重复，输入数组最大长度为2000，其中的元素最大为10**8。 arr是一个可能包含重复元素的整数数组，我们将这个数组分割成几个“块”，并将这些块分别进行排序。之后再连接起来，使得连接的结果和按升序排序后的原数组相同。 我们最多能将数组分成多少块？ 示例 1: 输入: arr = [5,4,3,2,1] 输出: 1 解释: 将数组分成2块或者更多块，都无法得到所需的结果。 例如，分成 [5, 4], [3, 2, 1] 的结果是 [4, 5, 1, 2, 3]，这不是有序的数组。 示例 2: 输入: arr = [2,1,3,4,4] 输出: 4 解释: 我们可以把它分成两块，例如 [2, 1], [3, 4, 4]。 然而，分成 [2, 1], [3], [4], [4] 可以得到最多的块数。 注意: arr的长度在[1, 2000]之间。 arr[i]的大小在[0, 10**8]之间。 思路  根据题意不难发现，我们分割成的块需要满足：第k-1一块的的最大元素小于等于第k块最小的元素。 存下每块最大元素，并统计存下元素个数，则为答案。  如何统计第k块的最大元素？ 利用单调栈的思想，稍微做点变形。遍历数组，\n 如果当前元素element大于等于栈顶元素，则直接入栈。 如果当前元素element小于栈顶元素，则记录下栈顶元素topMax（当前栈的最大元素）并将其推出。持续推出栈顶元素，直到element不小于当前栈顶元素，重新将topMax入栈。   单调栈.\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13  class Solution: def maxChunksToSorted(self, arr: List[int]) -\u0026gt; int: monotoneStack = [arr[0]] for i in range(1,len(arr)): element = arr[i] if element \u0026gt;= monotoneStack[-1]: monotoneStack.append(element) else: topMax = monotoneStack[-1] while monotoneStack and element \u0026lt; monotoneStack[-1]: monotoneStack.pop(-1) monotoneStack.append(topMax) return len(monotoneStack)   复杂度分析\n 时间复杂度：$O(n)$ 空间复杂度：$O(n)$  ","date":1607904000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1610906548,"objectID":"b83bf4f50eeda2a5a19ac2d504e5ec1e","permalink":"/resources/dsal/sliding-window/","publishdate":"2020-12-14T00:00:00Z","relpermalink":"/resources/dsal/sliding-window/","section":"resources","summary":"1456.定长子串中元音的最大数目 给你字符串 s 和整数 k 。 请返","tags":null,"title":"滑动窗口","type":"docs"},{"authors":null,"categories":null,"content":"并查集的数据结构  参考.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  class UF: def __init__(self, n:int): \u0026#34;\u0026#34;\u0026#34; n: 图中有多少个node \u0026#34;\u0026#34;\u0026#34; # 初始化: 每个node是自己的根节点 self.parent = [i for i in range(n)] # 初始化: 以自己为根节点的tree的size都是1 self.size = [1] * n # 初始化: 连通图的个数 self.count = n def find(self, node:int): while node != self.parent[node]: # 路径压缩 self.parent[node] = self.parent[self.parent[node]] node = self.parent[node] return node def union(self, p:int, q:int): pRoot = self.find(p) qRoot = self.find(q) if pRoot != qRoot: # 小树挂在大树上 if self.size[pRoot] \u0026gt;= self.size[qRoot]: self.parent[qRoot] = pRoot self.size[pRoot] += self.size[qRoot] self.size[qRoot] = None else: self.parent[pRoot] = qRoot self.size[qRoot] += self.size[pRoot] self.size[pRoot] = None self.count -= 1 def connected(self, p:int, q:int): return self.find(p) == self.find(q)   应用:\n 确定无向图的连通分量  题目 班上有 N 名学生。其中有些人是朋友，有些则不是。他们的友谊具有是传递性。如果已知 A 是 B 的朋友，B 是 C 的朋友，那么我们可以认为 A 也是 C 的朋友。所谓的朋友圈，是指所有朋友的集合。 给定一个 N * N 的矩阵 M，表示班级中学生之间的朋友关系。如果M[i][j] = 1，表示已知第 i 个和 j 个学生互为朋友关系，否则为不知道。你必须输出所有学生中的已知的朋友圈总数。 示例 1： 输入： [[1,1,0], [1,1,0], [0,0,1]] 输出：2 解释：已知学生 0 和学生 1 互为朋友，他们在一个朋友圈。 第2个学生自己在一个朋友圈。所以返回 2 。 示例 2： 输入： [[1,1,0], [1,1,1], [0,1,1]] 输出：1 解释：已知学生 0 和学生 1 互为朋友，学生 1 和学生 2 互为朋友，所以学生 0 和学生 2 也是朋友，所以他们三个在一个朋友圈，返回 1 。 提示： 1 \u0026lt;= N \u0026lt;= 200 M[i][i] == 1 M[i][j] == M[j][i] 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/friend-circles 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路一： 并查集 消化模板中\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  class UF: def __init__(self, n:int): \u0026#34;\u0026#34;\u0026#34; n: 图中有多少个node \u0026#34;\u0026#34;\u0026#34; # 初始化: 每个node是自己的根节点 self.parent = [i for i in range(n)] # 初始化: 以自己为根节点的tree的size都是1 self.size = [1] * n # 初始化: 连通图的个数 self.count = n def find(self, node:int): while node != self.parent[node]: # 路径压缩 self.parent[node] = self.parent[self.parent[node]] node = self.parent[node] return node def union(self, p:int, q:int): pRoot = self.find(p) qRoot = self.find(q) if pRoot != qRoot: # 小树挂在大树上 if self.size[pRoot] \u0026gt;= self.size[qRoot]: self.parent[qRoot] = pRoot self.size[pRoot] += self.size[qRoot] self.size[qRoot] = None else: self.parent[pRoot] = qRoot self.size[qRoot] += self.size[pRoot] self.size[pRoot] = None self.count -= 1 class Solution: def findCircleNum(self, M: List[List[int]]) -\u0026gt; int: n = len(M) uf = UF(n) if n == 0: return 0 for i in range(n): for j in range(i+1,n): if M[i][j] == 1: uf.union(i, j) return uf.count   复杂度:  时间：$O(n^2)$ 空间：$O(n)$  思路二: 无向图的搜索 BFS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  M = [[1, 0, 0, 0, 0, 1], [0, 1, 1, 0, 1, 0], [0, 1, 1, 1, 0, 0], [0, 0, 1, 1, 0, 0], [0, 1, 0, 0, 1, 0], [1, 0, 0, 0 ,0, 1]] class Solution: def findCircleNum(self, M): num_of_students = len(M) visited = [0] * num_of_students count = 0 queue = [] for i in range(num_of_students): print(\u0026#34;Explore node {}\u0026#34;.format(i)) if visited[i]: print(\u0026#34;node {} is visited\u0026#34;.format(i)) continue else: print(\u0026#34;node {} is unexplored\u0026#34;.format(i)) queue.append(i) print(\u0026#34;add node {} to queue | queue:{}\u0026#34;.format(i, queue)) visited[i] = 1 print(\u0026#34;mark node {} as visited\u0026#34;.format(i)) while queue: next_node_index = queue.pop(0) print(\u0026#34;node to be explored:{}\u0026#34;.format(next_node_index)) for j in range(i, num_of_students): if M[next_node_index][j] == 1 and visited[j] != 1: print(\u0026#34;node:{} and node:{} are connected!\u0026#34;.format(next_node_index, j)) queue.append(j) print(\u0026#34;add node {} to queue | queue:{}\u0026#34;.format(j, queue)) visited[j] = 1 print(\u0026#34;mark node {} as visited\u0026#34;.format(j)) count += 1 print(\u0026#34;====\u0026#34;) return count s = Solution() s.findCircleNum(M)   1319. 连通网络的操作次数 用以太网线缆将 n 台计算机连接成一个网络，计算机的编号从 0 到 n-1。线缆用 connections 表示，其中 connections[i] = [a, b] 连接了计算机 a 和 b。 网络中的任何一台计算机都可以通过网络直接或者间接访问同一个网络中其他任意一台计算机。 给你这个计算机网络的初始布线 connections，你可以拔开任意两台直连计算机之间的线缆，并用它连接一对未直连的计算机。请你计算并返回使所有计算机都连通所需的最少操作次数。如果不可能，则返回 -1 。 用以太网线缆将 n 台计算机连接成一个网络，计算机的编号从 0 到 n-1。线缆用 connections 表示，其中 connections[i] = [a, b] 连接了计算机 a 和 b。 网络中的任何一台计算机都可以通过网络直接或者间接访问同一个网络中其他任意一台计算机。 给你这个计算机网络的初始布线 connections，你可以拔开任意两台直连计算机之间的线缆，并用它连接一对未直连的计算机。请你计算并返回使所有计算机都连通所需的最少操作次数。如果不可能，则返回 -1 。 示例 1： 输入：n = 4, connections = [[0,1],[0,2],[1,2]] 输出：1 解释：拔下计算机 1 和 2 之间的线缆，并将它插到计算机 1 和 3 上。 示例 2： 输入：n = 6, connections = [[0,1],[0,2],[0,3],[1,2],[1,3]] 输出：2 示例 3： 输入：n = 6, connections = [[0,1],[0,2],[0,3],[1,2]] 输出：-1 解释：线缆数量不足。 示例 4： 输入：n = 5, connections = [[0,1],[0,2],[3,4],[2,3]] 输出：0 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/number-of-operations-to-make-network-connected 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路 思考如下几个问题:\n  什么时候无法把所有节点连接起来？当connections中给定的边的数量len(connections)少于无向图中的节点数量n时，一定无法构建一个连通图。当 len(connections)\u0026gt;n时， 我们一定知道可以通过移动某些边使得整个无向图连通。\n  我们需要多少次操作呢？考虑有n个孤立的节点，我们只需要操作n-1次，即可构建一个连通的无向图。同理，如果我们有k个连通集，则只需要k-1次操作。所有问题变成找一个无向图连通集的个数m。然后返回答案m-1。\n  代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  class UF: def __init__(self, n): self.parent = [i for i in range(n)] self.size = [1 for i in range(n)] self.count = n def find(self, p): while p != self.parent[p]: p = self.parent[p] # compression self.parent[p] = self.parent[self.parent[p]] return p def union(self, p, q): p_root = self.find(p) q_root = self.find(q) if p_root == q_root: return else: if self.size[p_root] \u0026gt;= self.size[q_root]: self.parent[q_root] = p_root self.size[p_root] += self.size[q_root] self.size[q_root] = None else: self.parent[p_root] = q_root self.size[q_root] += self.size[p_root] self.size[p_root] = None self.count -= 1 class Solution: def makeConnected(self, n: int, connections: List[List[int]]) -\u0026gt; int: nEdges = len(connections) # 线缆不足 if nEdges \u0026lt; n - 1: return -1 # 建立并查集 uf = UF(n) for edge in connections: p, q = edge[0], edge[1] uf.union(p, q) return uf.count - 1   复杂度  空间: $O(n)$ \u0026mdash;-\u0026gt; n: 节点数 时间: $O(n+m\\alpha(n))$ \u0026mdash;\u0026gt; m: 边的数量 \\alpha(n) inverse Ackermann function. 每次find的cost 是$O(\\alpha(n))$,几乎是一个常数。  ","date":1607904000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1608935668,"objectID":"cbd251955731c930ad5348989e6daeae","permalink":"/resources/dsal/union-find/","publishdate":"2020-12-14T00:00:00Z","relpermalink":"/resources/dsal/union-find/","section":"resources","summary":"并查集的数据结构 参考. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19","tags":null,"title":"Union Find 并查集","type":"docs"},{"authors":null,"categories":null,"content":"39. 组合总和 给定一个无重复元素的数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。 candidates 中的数字可以无限制重复被选取。 说明： 所有数字（包括 target）都是正整数。 解集不能包含重复的组合。 示例 1： 输入：candidates = [2,3,6,7], target = 7, 所求解集为： [ [7], [2,2,3] ] 示例 2： 输入：candidates = [2,3,5], target = 8, 所求解集为： [ [2,2,2,2], [2,3,3], [3,5] ] 提示： 1 \u0026lt;= candidates.length \u0026lt;= 30 1 \u0026lt;= candidates[i] \u0026lt;= 200 candidate 中的每个元素都是独一无二的。 1 \u0026lt;= target \u0026lt;= 500 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/combination-sum 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路 第一接触回溯，看了几个思路和代码模板。然后再配合剪枝的思想。理解不够深刻，画图来解释下。以后做多了再来总结。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  class Solution: def combinationSum(self, candidates: List[int], target: int) -\u0026gt; List[List[int]]: self.n = len(candidates) if self.n == 0: return [] # pruning candidates.sort() self.candidates = candidates self.ans = [] self.dfs(target, 0, []) return self.ans def dfs(self, target, start, path): if target == 0: self.ans.append(path.copy()) return for i in range(start, self.n): residual = target - self.candidates[i] if residual \u0026lt; 0: break path.append(self.candidates[i]) self.dfs(residual, i, path) path.pop() return   复杂度 带剪枝的不太会分析。。 不剪枝，得到一个非常不tight的上界是\n 时间: 设h = (target / min(candidates)) , n = len(candidates) 则 $O(n^h)$ 空间: 不考虑返回数组的情况下，空间复杂度为栈的深度，所以为 $O(h)$.  题目: 40. 组合总和 II 给定一个数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。 candidates 中的每个数字在每个组合中只能使用一次。 说明： 所有数字（包括目标数）都是正整数。 解集不能包含重复的组合。 示例 1: 输入: candidates = [10,1,2,7,6,1,5], target = 8, 所求解集为: [ [1, 7], [1, 2, 5], [2, 6], [1, 1, 6] ] 示例 2: 输入: candidates = [2,5,2,1,2], target = 5, 所求解集为: [ [1,2,2], [5] ] 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/combination-sum-ii 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路1: 建立带频次的 candidates的hash表 与39的思路几乎一样。区别在于：\n 每个元素不能无限次使用 candidates里面有重复的  用一个dict可同时解决这两个问题。其中key是candidates中的元素, value是candidates中这个数字出现的频次。这样在建立回溯“树”时，通过检查当前元素剩余次数，来决定能否继续利用该元素接着建树。举个例子\n如果 candidates = [2,3,2,5,6] 则可以建立一个dict ={\u0026quot;2\u0026quot;: 2, \u0026quot;3\u0026quot;:1, \u0026quot;5\u0026quot;:1, \u0026quot;6\u0026quot;:1}。 在建立回溯“树”时\u0026quot;2\u0026quot; 最多可以使用2次, \u0026ldquo;3\u0026rdquo;,\u0026ldquo;5\u0026rdquo;,\u0026ldquo;6\u0026quot;则最多能使用1次。\n同时，为了达到剪枝的目的，我们需要dict中key是升序排列。  代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  from collections import OrderedDict class Solution: def combinationSum2(self, candidates: List[int], target: int) -\u0026gt; List[List[int]]: if not candidates: return [] candidates.sort() self.freqTable = OrderedDict() self.ans = [] for num in candidates: if num not in self.freqTable.keys(): self.freqTable[num] = 1 else: self.freqTable[num] += 1 self.n_keys = len(self.freqTable) self.key_list = [* self.freqTable] self.dfs(target, [], 0) return self.ans def dfs(self, target, path, start): if target == 0: self.ans.append(path.copy()) return for i in range(start, self.n_keys): # 当前candidates 中需要考察的元素 num = self.key_list[i] # 该元素还可以继续使用 if self.freqTable[num] \u0026gt; 0: residual = target - num # 剪枝 if residual \u0026lt; 0: break else: self.freqTable[num] -= 1 path.append(num) self.dfs(residual, path, i) path.pop() self.freqTable[num] += 1 return   复杂度 带剪枝的不太会分析。。 不剪枝，得到一个非常不tight的上界是\n 时间: 设h 为树的深度, n = len(candidates) 则 $O(n^h)$ 空间: 不考虑返回数组的情况下，空间复杂度为栈的深度，所以为 $O(h)$.  思路二：lucifer的代码 根本没必要玩花的，只需要保证每次从target中减去的数和上一次减去的数不一样就好了。然后将index 向右移动一位避免重复使用。【其实没说清楚，看代码吧。。】\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  class Solution: def combinationSum2(self, candidates: List[int], target: int) -\u0026gt; List[List[int]]: \u0026#34;\u0026#34;\u0026#34; 与39题的区别是不能重用元素，而元素可能有重复； 不能重用好解决，回溯的index往下一个就行； 元素可能有重复，就让结果的去重麻烦一些； \u0026#34;\u0026#34;\u0026#34; size = len(candidates) if size == 0: return [] # 还是先排序，主要是方便去重 candidates.sort() path = [] res = [] self._find_path(candidates, path, res, target, 0, size) return res def _find_path(self, candidates, path, res, target, begin, size): if target == 0: res.append(path.copy()) else: for i in range(begin, size): left_num = target - candidates[i] if left_num \u0026lt; 0: break # 如果存在重复的元素，前一个元素已经遍历了后一个元素与之后元素组合的所有可能 if i \u0026gt; begin and candidates[i] == candidates[i-1]: continue path.append(candidates[i]) # 开始的 index 往后移了一格 self._find_path(candidates, path, res, left_num, i+1, size) path.pop()   47. 全排列II 给定一个可包含重复数字的序列 nums ，按任意顺序 返回所有不重复的全排列。 示例 1： 输入：nums = [1,1,2] 输出： [[1,1,2], [1,2,1], [2,1,1]] 示例 2： 输入：nums = [1,2,3] 输出：[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]] 提示： 1 \u0026lt;= nums.length \u0026lt;= 8 -10 \u0026lt;= nums[i] \u0026lt;= 10 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/permutations-ii 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  from copy import deepcopy class Solution: def permuteUnique(self, nums: List[int]) -\u0026gt; List[List[int]]: self.n = len(nums) if self.n == 0: return [] nums.sort() self.nums = nums self.ans = [] visited = [False] * self.n self.dfs(0, [], visited) return self.ans def dfs(self, i, path, visited): # i is the recursion depth counter if i == self.n: self.ans.append(deepcopy(path)) return for j in range(self.n): if visited[j]: continue if j \u0026gt; 0 and self.nums[j-1] == self.nums[j] and not visited[j-1]: continue visited[j] = True path.append(self.nums[j]) self.dfs(i+1, path, visited) visited[j] = False path.pop(-1) return   复杂度  时间复杂度 $O(n*n!)$ 空间复杂度 $O(n)$  401. 二进制手表 二进制手表顶部有 4 个 LED 代表 小时（0-11），底部的 6 个 LED 代表 分钟（0-59）。 每个 LED 代表一个 0 或 1，最低位在右侧。 例如，上面的二进制手表读取 “3:25”。 给定一个非负整数 n 代表当前 LED 亮着的数量，返回所有可能的时间。 示例： 输入: n = 1 返回: [\u0026quot;1:00\u0026quot;, \u0026quot;2:00\u0026quot;, \u0026quot;4:00\u0026quot;, \u0026quot;8:00\u0026quot;, \u0026quot;0:01\u0026quot;, \u0026quot;0:02\u0026quot;, \u0026quot;0:04\u0026quot;, \u0026quot;0:08\u0026quot;, \u0026quot;0:16\u0026quot;, \u0026quot;0:32\u0026quot;] 提示： 输出的顺序没有要求。 小时不会以零开头，比如 “01:00” 是不允许的，应为 “1:00”。 分钟必须由两位数组成，可能会以零开头，比如 “10:2” 是无效的，应为 “10:02”。 超过表示范围（小时 0-11，分钟 0-59）的数据将会被舍弃，也就是说不会出现 \u0026quot;13:00\u0026quot;, \u0026quot;0:61\u0026quot; 等时间。 思路 和找给定数组所有不重复的子集思路几乎一致，只不过需要写一个函数来将子集转换成时间，如果不符合要求舍弃即可。 具体的看代码。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  class Solution: def readBinaryWatch(self, num: int) -\u0026gt; List[str]: # 边界情况 if num == 0: return [\u0026#39;0:00\u0026#39;] # 将子集翻译成时间 def decode(path): m = h = 0 for idx in path: if idx \u0026lt;= 5: m += choices[idx] else: h += choices[idx] if h\u0026gt;=12 or m\u0026gt;=60: return None return ans.append(f\u0026#39;{h}:{str(m).zfill(2)}\u0026#39;) # path: 表示当前子集中元素的索引 # depth: 递归的深度 # start: 可以选取元素在数组中的引索 def dfs(path, depth, start): # 选取的子集大小符合要求了 if depth \u0026gt;= num: decode(path) return for i in range(start, 10): path.append(i) # 注意这里 start=i+1 是用于剪枝避免重复 # 举个例子 path = 【2，1】 和 path = 【1，2】 # 对最后结果没影响 dfs(path, depth+1, i+1) path.pop(-1) # 所有可选的数字 choices = [1,2,4,8,16,32,1,2,4,8] ans = [] dfs([], 0, 0) return ans   复杂度  时间复杂度：$O(nlog_2(n))$ 空间复杂度：$O(n)$  其中n是num中数字的个数。\n","date":1607731200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1610906548,"objectID":"f0f5a6de17250e5f93f2e8b1d2fbf2bf","permalink":"/resources/dsal/backtracking/","publishdate":"2020-12-12T00:00:00Z","relpermalink":"/resources/dsal/backtracking/","section":"resources","summary":"39. 组合总和 给定一个无重复元素的数组 candidates 和一个目标数 target ，找出 candidates 中","tags":null,"title":"Backtracking 回溯","type":"docs"},{"authors":null,"categories":null,"content":"前缀树的数据结构  参考.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  class Node: def __init__(self, val: str, isWord=False) -\u0026gt; None: self.val = val self.children = {} self.isWord = isWord class Trie: def __init__(self): \u0026#34;\u0026#34;\u0026#34; Initialize your data structure here. \u0026#34;\u0026#34;\u0026#34; self.root = Node(val=None) def insert(self, word: str) -\u0026gt; None: \u0026#34;\u0026#34;\u0026#34; Inserts a word into the trie. \u0026#34;\u0026#34;\u0026#34; node = self.root for char in word: if char not in node.children: node.children[char] = Node(val=char) node = node.children[char] node.isWord = True def search(self, word: str) -\u0026gt; bool: \u0026#34;\u0026#34;\u0026#34; Returns if the word is in the trie. \u0026#34;\u0026#34;\u0026#34; node = self.root for char in word: if char not in node.children: return False node = node.children[char] if node.isWord: return True return False def startsWith(self, prefix: str) -\u0026gt; bool: \u0026#34;\u0026#34;\u0026#34; Returns if there is any word in the trie that starts with the given prefix. \u0026#34;\u0026#34;\u0026#34; node = self.root for char in prefix: if char not in node.children: return False node = node.children[char] return True    时间复杂度：$O(n)$，n 是字符串长度， insert search startsWith 操作都是。 空间复杂度：$O(26^{h})$，h 是插入所有字符串最长的长度。  677. 键值映射 题目描述 实现一个 MapSum 类，支持两个方法，insert 和 sum： MapSum() 初始化 MapSum 对象 void insert(String key, int val) 插入 key-val 键值对，字符串表示键 key ，整数表示值 val 。如果键 key 已经存在，那么原来的键值对将被替代成新的键值对。 int sum(string prefix) 返回所有以该前缀 prefix 开头的键 key 的值的总和。 示例： 输入： [\u0026quot;MapSum\u0026quot;, \u0026quot;insert\u0026quot;, \u0026quot;sum\u0026quot;, \u0026quot;insert\u0026quot;, \u0026quot;sum\u0026quot;] [[], [\u0026quot;apple\u0026quot;, 3], [\u0026quot;ap\u0026quot;], [\u0026quot;app\u0026quot;, 2], [\u0026quot;ap\u0026quot;]] 输出： [null, null, 3, null, 5] 解释： MapSum mapSum = new MapSum(); mapSum.insert(\u0026quot;apple\u0026quot;, 3); mapSum.sum(\u0026quot;ap\u0026quot;); // return 3 (apple = 3) mapSum.insert(\u0026quot;app\u0026quot;, 2); mapSum.sum(\u0026quot;ap\u0026quot;); // return 5 (apple + app = 3 + 2 = 5) 提示： 1 \u0026lt;= key.length, prefix.length \u0026lt;= 50 key 和 prefix 仅由小写英文字母组成 1 \u0026lt;= val \u0026lt;= 1000 最多调用 50 次 insert 和 sum 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/map-sum-pairs 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路   题干中要求返回以该前缀 prefix 开头的键 key 的值的总和 \u0026mdash; 前缀树，空间换时间。使用前缀树模版。\n  insert(key, val): 将key中的每一个字符作为一个多叉树的node, 依次将node放入树中。最后需要在leaf node上记录 val， 并将其标记为一个单词的结尾。如果插入的重复的key, 只需跟新leaf node的值就好。\n  sum(prefix): 沿着多叉树找到以prefix最后一个字符结尾的node(如果存在)。利用层次遍历其所有的leaf node，然后将上面的数字求和便可得到答案。\n  代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  class Node: def __init__(self, key=None, isWord=False, val=None): self.key = key self.children = {} self.isWord = isWord self.val = None class MapSum: def __init__(self): \u0026#34;\u0026#34;\u0026#34; Initialize your data structure here. \u0026#34;\u0026#34;\u0026#34; self.root = Node() def insert(self, key: str, val: int) -\u0026gt; None: node = self.root for char in key: if char not in node.children: node.children[char] = Node(key=char) node = node.children[char] # the last node stores the last char in key, hence is a word node.isWord = True node.val = val def sum(self, prefix: str) -\u0026gt; int: node = self.root ans = 0 for char in prefix: if char not in node.children: return ans node = node.children[char] # the node stores the ending char in the prefix queue = [node] while queue: node = queue.pop(0) if node.isWord: ans += node.val for child in node.children: queue.append(node.children[child]) return ans   复杂度  时间 insert: $O(n)$, n \u0026mdash;\u0026gt; key这个字符串的长度 sum: $O(26^h)$, h\u0026mdash;\u0026gt; h为多叉树的高度。最差的情况prefix在root，树是一个满多叉树。 空间： $O(26^h)$  题目: 面试题 17.17. 多次搜索 给定一个较长字符串big和一个包含较短字符串的数组smalls，设计一个方法，根据smalls中的每一个较短字符串，对big进行搜索。输出smalls中的字符串在big里出现的所有位置positions，其中positions[i]为smalls[i]出现的所有位置。 示例： 输入： big = \u0026quot;mississippi\u0026quot; smalls = [\u0026quot;is\u0026quot;,\u0026quot;ppi\u0026quot;,\u0026quot;hi\u0026quot;,\u0026quot;sis\u0026quot;,\u0026quot;i\u0026quot;,\u0026quot;ssippi\u0026quot;] 输出： [[1,4],[8],[],[3],[1,4,7,10],[5]] 提示： 0 \u0026lt;= len(big) \u0026lt;= 1000 0 \u0026lt;= len(smalls[i]) \u0026lt;= 1000 smalls的总字符数不会超过 100000。 你可以认为smalls中没有重复字符串。 所有出现的字符均为英文小写字母。 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/multi-search-lcci 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路 1： 暴力搜索（超时） 对每个来自smalls中的wordsmall 遍历一次big去匹配。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  class Solution: def multiSearch(self, big: str, smalls: List[str]) -\u0026gt; List[List[int]]: nBig = len(big) ans = [] for idx, small in enumerate(smalls): ans.append([]) if small == \u0026#34;\u0026#34;: continue nSmall = len(small) idx_small = 0 prefix = small[idx_small] # find the occurence of the prefix of the small in big # print(\u0026#34;search for:\u0026#39;{}\u0026#39; | prefix:{}\u0026#34;.format(small, prefix)) for i in range(nBig): # print(\u0026#34;Seach the {}-th char in big to match prefix.\u0026#34;.format(i)) if big[i] == prefix: # print(\u0026#34; prefix matched!\u0026#34;) for j in range(i, i+nSmall): if j \u0026lt; nBig: if small[idx_small] == big[j]: idx_small += 1 else: break # match if idx_small == nSmall: # print(\u0026#34; matched\u0026#34;) ans[-1].append(i) # reset index to loop over small idx_small = 0 return ans     时间复杂度: $O(n_{big} * n_{smalls} * s_{max})$: 其中 $n_{big}$, $n_{smalls}$, $s_{max}$分别是 字符串big的长度，smalls 单词的个数，以及smalls中单词最大的长度。\n  空间复杂度：$O(1)$ (不算返回的数组)\n  思路 2：前缀树   用什么建树：第一反应是用 big的所有子字符串去建树，有如下问题\n 空间复杂度和最大长度有关，如果big很长，就很糟糕。 找所有子列是$O(2^{n_{big}})$的复杂度 所以用smalls中的字符串去建树。    怎么设计前缀树\n 除了套用模板记录 isWord 之外，我们需要用一个 属性idx 来表明当前这个字符(如果代表一个word)在smalls中的位置。    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  class Node: def __init__(self, idx=None): self.children = {} self.isWord = False self.idx = idx class Solution: def insert(self, word, idx): node = self.root for char in word: if char not in node.children: node.children[char] = Node() node = node.children[char] # reach the end of the word node.idx = idx node.isWord = True def multiSearch(self, big: str, smalls: List[str]) -\u0026gt; List[List[int]]: n = len(smalls) self.root = Node() ans = [] # build the trie for i in range(n): self.insert(smalls[i], i) ans.append([]) # begin search nBig = len(big) for i in range(nBig): node = self.root for j in range(i, nBig): current_char = big[j] # no match if current_char not in node.children: break if node.children[current_char].isWord: ans[node.children[current_char].idx].append(i) node = node.children[current_char] return ans    时间复杂度:  建树: $O(n_{small} * s_{max})$ 搜索: $O(s_{max} * n_{big})$ 显著的比暴力的 $O(n_{big} * n_{smalls} * s_{max})$ 节约时间   空间复杂度：  建树：$O(n_{small} * s_{max})$    ","date":1607731200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1607967296,"objectID":"a22f3329d5734d0323a4befe77dd4d3c","permalink":"/resources/dsal/trie/","publishdate":"2020-12-12T00:00:00Z","relpermalink":"/resources/dsal/trie/","section":"resources","summary":"前缀树的数据结构 参考. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19","tags":null,"title":"Trie 前缀树","type":"docs"},{"authors":null,"categories":null,"content":"560. 和为k的子数组 给定一个整数数组和一个整数 k，你需要找到该数组中和为 k 的连续的子数组的个数。 示例 1 : 输入:nums = [1,1,1], k = 2 输出: 2 , [1,1] 与 [1,1] 为两种不同的情况。 说明 : 数组的长度为 [1, 20,000]。 数组中元素的范围是 [-1000, 1000] ，且整数 k 的范围是 [-1e7, 1e7]。 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/subarray-sum-equals-k 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路 最直观的想法便是给定了 start与end ，对子数组num[start:end]里的元素求和。如果和为k则说明找到一组符合条件的子数组。但是这样的复杂度为$O(n^3)$。\n初次优化 观察到\n1  sum(num[start-1:end]) + num[start] = sum(num[start:end])   我们可以固定住end 然后让 start从 end开始递减到0，对在这个循环过程中得到子列和与k比较并统计符合条件的子列数量。\n这样的话时间复杂度为$O(n^2)$. 可惜Python的版本会超时。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  class Solution(object): def subarraySum(self, nums, k): \u0026#34;\u0026#34;\u0026#34; :type nums: List[int] :type k: int :rtype: int \u0026#34;\u0026#34;\u0026#34; total = 0 if not nums: return total n = len(nums) for end in range(n): tempSum = 0 for start in range(end, -1, -1): tempSum += nums[start] if tempSum == k: total += 1 return total   再次优化 假设我们有个数列cumSum其中cumsum[i]是num中前i个数的和，比如\ncumSum[0] = num[0] cumSum[1] = num[0] + num[1] .... 更加紧凑的我们有 cumSum[0] = num[0] cumSum[i] = num[i] + cumSum[i-1], i \u0026gt;= 1 对于满足的条件的子列(从start开始，到end结束 )，那么我们有\nk = sum(num[start:end]) = cumSum[end] - cumSum[start-1] ---\u0026gt; cumSum[start-1] = cumSum[end] - k 本质就是寻找 从0 到 end 有多少个 index i 使得 cumSum[i]  为k。 之前的方法是用循环，这里考虑用哈希表dic。在建立cumSum这个数组的时候，我们 可以以 cumSum[i] 为key 以 cumSum[i] 出现的频次为value。 那么对于以end结束的子列，满足条件的子列有dic[cumSum[end] - k ]。\n最后两个小细节：\n 边界情况。num[end] 直接为k。我们在初始化哈希表时，需要加入一个 以0为key 以 1为value的key-value pair。 我们不需要维护一个数组cumSum[i]  而是用一个变量就够了。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  from collections import defaultdict class Solution(object): def subarraySum(self, nums, k): \u0026#34;\u0026#34;\u0026#34; :type nums: List[int] :type k: int :rtype: int \u0026#34;\u0026#34;\u0026#34; if not nums: return 0 total = 0 n = len(nums) cumSum = 0 cumSumFreq = defaultdict() # 边界条件：什么都不选的时候 cumulative sum 为 0 cumSumFreq[0] = 1 for start in range(n): cumSum += nums[start] total += cumSumFreq.get(cumSum - k, 0) # 更新字典必须在求和之后 cumSumFreq[cumSum] = cumSumFreq.get(cumSum, 0) + 1 return total   时间复杂度： $O(n)$ 空间复杂度： $O(n)$\n","date":1607472000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1607967296,"objectID":"b36af9ea3904b55bd6e8c0dee242d78b","permalink":"/resources/dsal/prefix-sum/","publishdate":"2020-12-09T00:00:00Z","relpermalink":"/resources/dsal/prefix-sum/","section":"resources","summary":"560. 和为k的子数组 给定一个整数数组和一个整数 k，你需要找到该数","tags":null,"title":"Prefix Sum","type":"docs"},{"authors":null,"categories":null,"content":"268. 丢失的数字 给定一个包含 [0, n] 中 n 个数的数组 nums ，找出 [0, n] 这个范围内没有出现在数组中的那个数。 进阶： 你能否实现线性时间复杂度、仅使用额外常数空间的算法解决此问题? 示例 1： 输入：nums = [3,0,1] 输出：2 解释：n = 3，因为有 3 个数字，所以所有的数字都在范围 [0,3] 内。2 是丢失的数字，因为它没有出现在 nums 中。 示例 2： 输入：nums = [0,1] 输出：2 解释：n = 2，因为有 2 个数字，所以所有的数字都在范围 [0,2] 内。2 是丢失的数字，因为它没有出现在 nums 中。 示例 3： 输入：nums = [9,6,4,2,3,5,7,0,1] 输出：8 解释：n = 9，因为有 9 个数字，所以所有的数字都在范围 [0,9] 内。8 是丢失的数字，因为它没有出现在 nums 中。 示例 4： 输入：nums = [0] 输出：1 解释：n = 1，因为有 1 个数字，所以所有的数字都在范围 [0,1] 内。1 是丢失的数字，因为它没有出现在 nums 中。 提示： n == nums.length 1 \u0026lt;= n \u0026lt;= 104 0 \u0026lt;= nums[i] \u0026lt;= n nums 中的所有数字都 独一无二 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/missing-number 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路1: 数学加减法 对[0,n]求和 然后减去sum(numse) 即为答案\n1 2 3 4  class Solution: def missingNumber(self, nums: List[int]) -\u0026gt; int: n = len(nums) return int(n * (n+1) / 2) - sum(nums)    时间复杂度：$O(n)$ 空间复杂度：$O(1)$  思路2: 异或XOR运算 用到的异或运算法则：\n a ^ a = 0 a^b^c=a^c^b a ^ b ^ c = a ^ (b ^ c) = (a ^ b) ^ c  考虑\nnums = [0,2,3] index = [0,1,2,3] 1 = (0^0)^1^(2^2)^(3^3) = (0^2^3) ^ (0^1^2^3) 因此便有如下代码\n1 2 3 4 5 6 7  class Solution: def missingNumber(self, nums: List[int]) -\u0026gt; int: n = len(nums) ans = n for i in range(n): ans ^= (i^nums[i]) return ans    时间复杂度：$O(n)$ 空间复杂度：$O(1)$  面试题 01.01. 判定字符是否唯一 实现一个算法，确定一个字符串 s 的所有字符是否全都不同。 示例 1： 输入: s = \u0026quot;leetcode\u0026quot; 输出: false 示例 2： 输入: s = \u0026quot;abc\u0026quot; 输出: true 限制： 0 \u0026lt;= len(s) \u0026lt;= 100 如果你不使用额外的数据结构，会很加分。 思路 基本思路如下\n 创建一个长度为26的array并初始为全0值，a-z 各自对应 0-25. 遍历astr，对当前字符char在array中对应位置的元素加1。 在遍历过程中，如果array中有位置出现2，则说明出现了重复的值。否则无重复。  如果我们用0表示一个字符尚未出现，1表示字符已经出现了，则上述操作可以全部使用 位运算完成。\n 创建一个长度为26的array并初始为全0值: 创建一个变量seen, 并初始为0。 对当前字符char在array中对应位置的元素加1： 计算当前字符char与a的距离为d, 利用 seen | 1\u0026lt;\u0026lt;(d+1)。 如果array中有位置出现2: 计算当前字符char与a的距离为d, 利用 seen \u0026amp; 1\u0026lt;\u0026lt;(d+1) 。  代码 1 2 3 4 5 6 7 8 9 10 11 12 13  class Solution: def isUnique(self, astr: str) -\u0026gt; bool: seen = 0 origin = ord(\u0026#39;a\u0026#39;) for char in astr: d = ord(char) - origin + 1 temp = 1 \u0026lt;\u0026lt; d # 如果 返回 True, 则说明 char 已经出现过了 if seen \u0026amp; temp == temp: return False # 标记 char 为被发现 seen = seen | temp return True   复杂度分析：  时间复杂度：$O(n)$ 空间复杂度：$O(1)$  leetcode 78: 子集 题目描述\n给定一组不含重复元素的整数数组 nums，返回该数组所有可能的子集（幂集）。 说明：解集不能包含重复的子集。 示例: 输入: nums = [1,2,3] 输出: [ [3], [1], [2], [1,2,3], [1,3], [2,3], [1,2], [] ] 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/subsets 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路 数学上来说，每个元素存在选和不选两个可能性，所以一共有2^n种结果，其中n是nums 元素中的个数。 问题变成了枚举[0, 2^n-1]的二进制表达。举个例子\nnums = [3,2,1] ---\u0026gt; 8 = 2^3 中可能 每种可能对应的二进制表示如下 1. 000 [] 2. 001 [1] 3. 010 [2] 4. 011 [1,2] 5. 100 [3] 6. 101 [1,3] 7. 110 [1,2] 8. 111 [1,2,3] 但是如何用计算机语言来，尤其是利用位运算来枚举上述所有情况呢。因为对这个不熟，参考了 这里的处理方式。\n举个例子\n110 从右往左(0-indexed)在第1和第2位置出现了1. 如何用位运算找到呢？ 每次向右移动n个bit然后和 1 做 “并” 运算，便可知道第n位是否为1。 举个例子 将110向右移动0个bit: 110\u0026gt;\u0026gt;0 ---\u0026gt; 110. 110 \u0026amp; 001 ---\u0026gt; 0: 说明第0位不为1 将110向右移动1个bit: 110\u0026gt;\u0026gt;1 ---\u0026gt; 011. 011 \u0026amp; 001 ---\u0026gt; 1: 说明第1位为1 将110向右移动2个bit: 110\u0026gt;\u0026gt;2 ---\u0026gt; 001. 001 \u0026amp; 001 ---\u0026gt; 1: 说明第2位为1 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  class Solution(object): def subsets(self, nums): \u0026#34;\u0026#34;\u0026#34; :type nums: List[int] :rtype: List[List[int]] \u0026#34;\u0026#34;\u0026#34; n = len(nums) numElements = 1 \u0026lt;\u0026lt; n ans = [0] * numElements for mask in range(numElements): # 寻找 mask 的二进制表达中 1出现的位置 # 因为我们一共有n个数字在nums中， 所以2^n # 有n个bits。 从而最左位数最多能向右移动n-1次 temp = [] for rightShift in range(n): # 从右往左数，mask的第rightShift位刚好是1 if (mask \u0026gt;\u0026gt; rightShift) \u0026amp; 1 == 1: temp.append(nums[rightShift]) ans[mask] = temp return ans   复杂度  时间：$O(n2^n)$  for mask in range(numElements): $2^n$  for rightShift in range(n):: $n$   空间: 不算返回数组是 $O(n)$  ","date":1607126400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1610906548,"objectID":"8961a33d894ed7ce70cd6c8044f503ab","permalink":"/resources/dsal/bit-operations/","publishdate":"2020-12-05T00:00:00Z","relpermalink":"/resources/dsal/bit-operations/","section":"resources","summary":"268. 丢失的数字 给定一个包含 [0, n] 中 n 个数的数组 nums ，找出 [0, n] 这个范","tags":null,"title":"Bit operations","type":"docs"},{"authors":null,"categories":null,"content":"Heap Basics We consider the minHeap with n elements being stored.\nminHeap, is a complete binary tree, which can be stored in an array A.\nProperties:\n Given the index of the element in the array A, the left child and right children of A[i] are A[2i+1] and A[2i+2] respectively. The parent of A[i] is A[floor(i-1)/2]. (Heap Property)Excluding the root A[0], A[parent[i]] \u0026lt;= A[i] for all $i\u0026gt;0$.  Basic operations\n  parent(i): return the parent of the node $i$.\n  left(i): return the left children of the node $i$.\n  right(i): return the right children of the node $i$.\n  insert(element): $O(\\log(n))$. Put the inserted element at the end of the array. If it\u0026rsquo;s larger than its parent, then there is nothing left to do. Otherwise, swap it with its parent. Repeat this process until either the inserted element becomes the first element of the array or find a parent which is smaller than the inserted element.\n  delete(): $O(\\log(n))$. Place the root element in a variable to return later. Remove the last element in the deepest level and move it to the root. While the moved element has a value greater than at least one of its children, swap this value with the smaller-valued child. Return the original root that was saved.\n  heapify and build-heap\n  heapify(A,i): Matain the Heap Property of a subtree rooted at i. Its inputs are an array A and an index i into the array. When heapify(A,i) is called, it is assumed that the binary trees rooted at left(i) and right(i) are minHeaps, but that A[i] may be larger than its children, thus violating theHeap Property. The function of heapify(A,i) is to let the value at A[i] \u0026ldquo;float down\u0026rdquo; in the heap so that the subtree rooted at index i becomes a heap. To achieve this, you just need to compare A[i] with A[left(i)] and A[right(i)] and swap when necessary. (Similart to delete() but nothing is deleted.) The complexity is $O(\\texttt{height}(i))$, where $\\texttt{height}(i)$ is the height of node i in the tree.\n  build-heap(L): Its input is an unsorted array L with size n. Then do the following.\n for i := floor(n/2) downto 1 do HEAPIFY(L, i); end for The last floor(n/2) elements of height 0, hence already are minHeap themselves. The total time comlexity is $$ \\sum_{h=1}^{\\log_2(n)} \\lceil \\frac{n}{2^{h+1}}\\rceil * O(\\log_2(h)) = O(n). $$\n  215 数组中第k个最大元素 在未排序的数组中找到第 k 个最大的元素。请注意，你需要找的是数组排序后的第 k 个最大的元素，而不是第 k 个不同的元素。 示例 1: 输入: [3,2,1,5,6,4] 和 k = 2 输出: 5 示例 2: 输入: [3,2,3,1,2,4,5,5,6] 和 k = 4 输出: 4 说明: 你可以假设 k 总是有效的，且 1 ≤ k ≤ 数组的长度。 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/kth-largest-element-in-an-array 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路  利用前k个数构造一个大小为k的minHeap 从第k+1个数开始将其与minHeap中的root相比较，如果比root大则移除root并插入该元素 （同时维持minHeap的性质） 遍历完成后，minHeap中为最大的k个数，且第k大的数在root  代码 1 2 3 4 5 6 7 8 9  import heapq class Solution: def findKthLargest(self, nums: List[int], k: int) -\u0026gt; int: minHeap = nums[:k] heapq.heapify(minHeap) for i in nums[k:]: if i \u0026gt; minHeap[0]: heapq.heappushpop(minHeap, i) return minHeap[0]   复杂度  时间$O(k + (n-k)logk)$:  建大小为k的minHeap: $O(k)$ 比较并(可能插入)n-k个元素: $O((n-k)log(k))$   空间复杂度 $O(k)$  1046. 最后一块石头的重量 有一堆石头，每块石头的重量都是正整数。 每一回合，从中选出两块 最重的 石头，然后将它们一起粉碎。假设石头的重量分别为 x 和 y，且 x \u0026lt;= y。那么粉碎的可能结果如下： 如果 x == y，那么两块石头都会被完全粉碎； 如果 x != y，那么重量为 x 的石头将会完全粉碎，而重量为 y 的石头新重量为 y-x。 最后，最多只会剩下一块石头。返回此石头的重量。如果没有石头剩下，就返回 0。 示例： 输入：[2,7,4,1,8,1] 输出：1 解释： 先选出 7 和 8，得到 1，所以数组转换为 [2,4,1,1,1]， 再选出 2 和 4，得到 2，所以数组转换为 [2,1,1,1]， 接着是 2 和 1，得到 1，所以数组转换为 [1,1,1]， 最后选出 1 和 1，得到 0，最终数组转换为 [1]，这就是最后剩下那块石头的重量。 提示： 1 \u0026lt;= stones.length \u0026lt;= 30 1 \u0026lt;= stones[i] \u0026lt;= 1000 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/last-stone-weight 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路 1.构建一个maxHeap 2.每次从maxHeap中pop两个出来(如果有元素的话) 3.如果y-x\u0026gt;0 则push进maxHeap直到maxHeap为空\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  import heapq class Solution: def lastStoneWeight(self, stones: List[int]) -\u0026gt; int: if not stones: return 0 maxHeap = [-i for i in stones] heapq.heapify(maxHeap) while len(maxHeap) \u0026gt; 1: y = -heapq.heappop(maxHeap) x = -heapq.heappop(maxHeap) if x != y: heapq.heappush(maxHeap, x-y) if not maxHeap: return 0 else: return -maxHeap[0]   复杂度  时间复杂度：$O(nlog_2n)$ 空间复杂度：$O(n)$  23. 合并k个升序链表 给你一个链表数组，每个链表都已经按升序排列。 请你将所有链表合并到一个升序链表中，返回合并后的链表。 示例 1： 输入：lists = [[1,4,5],[1,3,4],[2,6]] 输出：[1,1,2,3,4,4,5,6] 解释：链表数组如下： [ 1-\u0026gt;4-\u0026gt;5, 1-\u0026gt;3-\u0026gt;4, 2-\u0026gt;6 ] 将它们合并到一个有序链表中得到。 1-\u0026gt;1-\u0026gt;2-\u0026gt;3-\u0026gt;4-\u0026gt;4-\u0026gt;5-\u0026gt;6 示例 2： 输入：lists = [] 输出：[] 示例 3： 输入：lists = [[]] 输出：[] 提示： k == lists.length 0 \u0026lt;= k \u0026lt;= 10^4 0 \u0026lt;= lists[i].length \u0026lt;= 500 -10^4 \u0026lt;= lists[i][j] \u0026lt;= 10^4 lists[i] 按 升序 排列 lists[i].length 的总和不超过 10^4 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/merge-k-sorted-lists 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路一： 暴力合并k个链表 遍历lists里所有的链表，然后套用合并两个链表的模板。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  # Definition for singly-linked list. # class ListNode: # def __init__(self, val=0, next=None): # self.val = val # self.next = next class Solution: def mergeKLists(self, lists: List[ListNode]) -\u0026gt; ListNode: if not lists: return None n = len(lists) merged = lists[0] for i in range(1, n): tobeMerge = lists[i] l1 = merged l2 = tobeMerge ans = ListNode() cur = ans while l1 and l2: if l1.val \u0026lt;= l2.val: cur.next = l1 l1 = l1.next else: cur.next = l2 l2 = l2.next cur = cur.next if l1 is None: cur.next = l2 else: cur.next = l1 merged = ans.next return merged   复杂度  时间复杂度: 假设lists里有k个链表，n为k个链表的最大长度。则时间复杂度为$O(k^2n)$ 空间复杂度: $O(1)$  最小堆 思路 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  import heapq # override default method for LitsNode class. def __lt__(self, other): return self.val \u0026lt; other.val def __le__(self, other): return self.val \u0026lt; other.val ListNode.__lt__ = __lt__ ListNode.__le__ = __le__ class Solution: def mergeKLists(self, lists: List[ListNode]) -\u0026gt; ListNode: minHeap = [] # 本来想用heapify但是存在[[],[]]输入。。。 for node in lists: if node: heapq.heappush(minHeap, node) ans = ListNode() cur = ans while minHeap: curMin = heapq.heappop(minHeap) cur.next = curMin cur = cur.next if curMin.next: heapq.heappush(minHeap, curMin.next) return ans.next   复杂度  时间复杂度: 假设lists里有k个链表，n为k个链表的最大长度。则时间复杂度为$O(nk\\log_2k)$ 空间复杂度: $O(k)$ \u0026mdash; minHeap的大小  378. 有序矩阵中第k小的元素 给定一个 n x n 矩阵，其中每行和每列元素均按升序排序，找到矩阵中第 k 小的元素。 请注意，它是排序后的第 k 小元素，而不是第 k 个不同的元素。 示例： matrix = [ [ 1, 5, 9], [10, 11, 13], [12, 13, 15] ], k = 8, 返回 13。 提示： 你可以假设 k 的值永远是有效的，1 ≤ k ≤ n2 。 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/kth-smallest-element-in-a-sorted-matrix 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路1: 遍历 + maxHeap 遍历整个矩阵，构建并维护一个大小为k的maxHeap。只有当新元素比堆顶的元素（堆中最大的元素）小的时候才将堆顶元素弹出，新元素压入。这样可以保证遍历完矩阵后，堆顶的元素为第k小的元素。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  import heapq class Solution: def kthSmallest(self, matrix: List[List[int]], k: int) -\u0026gt; int: if not matrix or not matrix[0]: return 0 self.maxHeap = [] n = len(matrix) for i in range(n): for j in range(n): self.addElement(matrix[i][j], k) return -self.maxHeap[0] def addElement(self, e, k): if len(self.maxHeap) \u0026lt; k: heapq.heappush(self.maxHeap, -e) else: if e \u0026lt; -self.maxHeap[0]: out = heapq.heappushpop(self.maxHeap, -e)   复杂度  时间: $O(n^2log_2k)$ \u0026mdash; 每个元素都被压入(弹出)maxHeap中。 空间: $O(k)$ \u0026mdash; 维护一个大小为k的maxHeap.  时间和空间复杂度会比将整个二维矩阵变为一维数列再排序要好。\n模仿合并k个升序链表（23） 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  import heapq class Solution: def kthSmallest(self, matrix: List[List[int]], k: int) -\u0026gt; int: if not matrix or not matrix[0]: return 0 j = 0 n = len(matrix) minHeap = [(matrix[i][j], i, j) for i in range(n)] heapq.heapify(minHeap) print(minHeap) while k \u0026gt; 0: head = heapq.heappop(minHeap) i,j = head[1], head[2] if j \u0026lt;= n-2: heapq.heappush(minHeap, (matrix[i][j+1], i, j+1)) k -= 1 return head[0]   复杂度  时间: $O(n+k\\log_2n)$ \u0026mdash; $O(n)$建minHeap; $O(k\\log_2n)$ 压入弹出k个元素。最坏的情况下$k=n^2$. 空间: $O(n)$ \u0026mdash; 维护一个大小为n的minHeap.  思路三： 二分法（官方题解） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  class Solution: def kthSmallest(self, matrix: List[List[int]], k: int) -\u0026gt; int: def search(target, n): ans = 0 i = n - 1 j = 0 while i \u0026gt;= 0 and j \u0026lt; n: if matrix[i][j] \u0026lt;= target: # elements from matrix[0][j] to matrix[i][j] # are smaller than the target ans += (i + 1) # there are i+1 elements in selected column qualified # check the next column j += 1 else: i -= 1 return ans if not matrix or not matrix[0]: return 0 n = len(matrix) left, right = matrix[0][0], matrix[n-1][n-1] count = n * n + 1 while left\u0026lt;right: mid = (left + right) // 2 count = search(mid, n) if count \u0026lt; k: left = mid + 1 else: right = mid return left   复杂度  时间: $O(nlog_2(r-l))$ \u0026mdash; l, r分别为矩阵中最大最小元素 空间: $O(1)$  1054 条形码 在一个仓库里，有一排条形码，其中第 i 个条形码为 barcodes[i]。 请你重新排列这些条形码，使其中两个相邻的条形码 不能 相等。 你可以返回任何满足该要求的答案，此题保证存在答案。 示例 1： 输入：[1,1,1,2,2,2] 输出：[2,1,2,1,2,1] 示例 2： 输入：[1,1,1,1,2,2,3,3] 输出：[1,3,1,3,2,1,2,1] 提示： 1 \u0026lt;= barcodes.length \u0026lt;= 10000 1 \u0026lt;= barcodes[i] \u0026lt;= 10000 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/distant-barcodes 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路 第一反应，见缝插针。举个例子\nbarcodes: [1,1,1,1,2,2,2,3,3] 1 出现的频次最多, 所以我们希望用2，3来将其分割开。那些位置可以插入呢? 下图横线中位置都可放入 _ 1 _ 1 _ 1 _ 1 _ 考虑一种插入 _ 1 _ 2 _ 1 _ 2 _ 1 _ 2 _ 但是每次去记录可以插入的位置以及可以插入的数字是很头痛的事情。其实上述思路有可以稍微修改一下，优先使用barcodes出现频次最高的，后面接上一个出现频次第二高的。 用画图的方式来阐述这个点。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  import heapq from collections import Counter class Solution: def rearrangeBarcodes(self, barcodes: List[int]) -\u0026gt; List[int]: # edge case if len(barcodes) == 1: return barcodes c = Counter(barcodes) # create (freq, label) pairs maxHeap = [(-i[1], i[0]) for i in c.items()] heapq.heapify(maxHeap) ans = [] while len(maxHeap) \u0026gt;= 2: pair1 = heapq.heappop(maxHeap) pair2 = heapq.heappop(maxHeap) ans.append(pair1[1]) ans.append(pair2[1]) if -pair1[0] - 1 \u0026gt; 0: heapq.heappush(maxHeap, (pair1[0]+1, pair1[1])) if -pair2[0] - 1 \u0026gt; 0: heapq.heappush(maxHeap, (pair2[0]+1, pair2[1])) if len(maxHeap) == 1: # only one pair left in the maxHeap and the freq is # guaranteed to be 1 ans.append(maxHeap[0][1]) return ans   复杂度  时间复杂度：$O(n\\log_2n)$  统计频次 $O(n)$ 建堆 $O(n)$ 每个元素出堆 $O(n\\log_2n)$   空间复杂度: $O(n)$  ","date":1607126400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1609713712,"objectID":"12f2a8626128236a15e8b85661a1e0cb","permalink":"/resources/dsal/heap/","publishdate":"2020-12-05T00:00:00Z","relpermalink":"/resources/dsal/heap/","section":"resources","summary":"Heap Basics We consider the minHeap with n elements being stored. minHeap, is a complete binary tree, which can be stored in an array A. Properties: Given the index of","tags":null,"title":"Heap","type":"docs"},{"authors":null,"categories":null,"content":"","date":1607126400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1607967296,"objectID":"a55ba8aa95c13fa4f0157c7a4c296296","permalink":"/resources/dsal/tree/","publishdate":"2020-12-05T00:00:00Z","relpermalink":"/resources/dsal/tree/","section":"resources","summary":"","tags":null,"title":"Tree and Graph","type":"docs"},{"authors":null,"categories":null,"content":"Compile your code in command line  Reference: Pitt-Francis, J., \u0026amp; Whiteley, J. (2017). Guide to Scientific Computing in C++ Secon Edition. Springer.\n compiler [-flag1 -flag2 ...] -o excutableFileName sourceCodeFile   Compiler: g++\n  Compiler flags:\n -Wall: list out anything unexpected that is not actually an error, but will still create an executable file. -O: (upper case o): optimize the executable file at the cost of longer compilation time -g: compile code with debugging information preserved -o: use this to allow name the excutable file name    Inputs:\n excutableFileName: the parameter provided to the flag -o sourceCodeFile: the cpp file which you want to compile    1  g++ -Wall -O -o addTwoNumbers addTwoNumbers.cpp   ","date":1597536000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609713712,"objectID":"00ec439825509f777e40c20da9ff8ce2","permalink":"/resources/cpp_laopt/cpp/makefile/","publishdate":"2020-08-16T00:00:00Z","relpermalink":"/resources/cpp_laopt/cpp/makefile/","section":"resources","summary":"Compile your code in command line  Reference: Pitt-Francis, J., \u0026amp; Whiteley, J. (2017). Guide to Scientific Computing in C++ Secon Edition. Springer.\n compiler [-flag1 -flag2 ...] -o excutableFileName sourceCodeFile   Compiler: g++","tags":null,"title":"Compile your program","type":"docs"},{"authors":null,"categories":null,"content":"Traverse Algorithms Pre-order The pre-order traversal visit nodes in root - left - right order, where the the root appears in the first.\nrecursion implementation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # Definition for a binary tree node. # class TreeNode(object): # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class Solution(object): def preorderTraversal(self, root): \u0026#34;\u0026#34;\u0026#34; :type root: TreeNode :rtype: List[int] \u0026#34;\u0026#34;\u0026#34; self.ans = [] self.dfs(root) return self.ans def dfs(self, node): if not node: return self.ans.append(node.val) if node.left: self.dfs(node.left) if node.right: self.dfs(node.right)   iterative implementation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # iterative # hint: using stack and add children using right-left order. from collections import deque class Solution(object): def preorderTraversal(self, root): \u0026#34;\u0026#34;\u0026#34; :type root: TreeNode :rtype: List[int] \u0026#34;\u0026#34;\u0026#34; if not root: return [] stack = deque() stack.appendleft(root) ans = [] while stack: node = stack.popleft() ans.append(node.val) if node.right: stack.appendleft(node.right) if node.left: stack.appendleft(node.left) return ans   In-order The in-order traversal visit nodes in left-root-right order, where the the root appears in the middle. recursion implementation\nRecursion 1 2 3 4 5 6 7 8 9 10 11 12 13 14  class Solution(object): def inorderTraversal(self, root): \u0026#34;\u0026#34;\u0026#34; :type root: TreeNode :rtype: List[int] \u0026#34;\u0026#34;\u0026#34; self.ans = [] self.dfs(root) return self.ans def dfs(self, node): if not node: return if node.left: self.dfs(node.left) self.ans.append(node.val) if node.right: self.dfs(node.right)   iterative implementation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  from collections import deque class Solution(object): def inorderTraversal(self, root): \u0026#34;\u0026#34;\u0026#34; :type root: TreeNode :rtype: List[int] \u0026#34;\u0026#34;\u0026#34; if not root: return [] self.stack = deque() ans = [] while root or self.stack: # need add root here while root: self.stack.appendleft(root) root = root.left node = self.stack.popleft() ans.append(node.val) root = node.right return ans   discussion: why the following code is wrong?\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  from collections import deque class Solution(object): def inorderTraversal(self, root): \u0026#34;\u0026#34;\u0026#34; :type root: TreeNode :rtype: List[int] \u0026#34;\u0026#34;\u0026#34; if not root: return [] self.stack = deque() self.stack.appendleft(root) ans = [] while root or self.stack: while root: if root.left: self.stack.appendleft(root.left) root = root.left node = self.stack.popleft() ans.append(node.val) root = node.right return ans   Hint: following edge cases would fail. 1 \\ 2 / 3 When the node 1 is poped out of the stack. The stack is empty. But we still need to explore its right child.\nPost-order The post-order traversal visit nodes in left-right-root order, where the the root appears in the last.\nrecursion implementation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  class Solution(object): def postorderTraversal(self, root): \u0026#34;\u0026#34;\u0026#34; :type root: TreeNode :rtype: List[int] \u0026#34;\u0026#34;\u0026#34; self.ans = [] self.dfs(root) return self.ans def dfs(self, node): if not node: return [] if node.left: self.dfs(node.left) if node.right: self.dfs(node.right) self.ans.append(node.val)   iterative implementation The idea is to hack the pre-order traversal, which visit nodes in root-left-right order. If we visit in the root-right-left order and reverse it, then we get left-right-root order.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  from collections import deque class Solution(object): def postorderTraversal(self, root): \u0026#34;\u0026#34;\u0026#34; :type root: TreeNode :rtype: List[int] \u0026#34;\u0026#34;\u0026#34; while not root: return [] ans = [] stack = deque() stack.appendleft(root) while stack: # root-right-left order # reverse it; left-right-root node = stack.popleft() ans.append(node.val) if node.left: stack.appendleft(node.left) if node.right: stack.appendleft(node.right) return ans[::-1]   Summary: templates recursion iterative  Reference\nLevel-order From left to right from root to leaf.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  from collections import deque class Solution(object): def levelOrder(self, root): \u0026#34;\u0026#34;\u0026#34; :type root: TreeNode :rtype: List[List[int]] \u0026#34;\u0026#34;\u0026#34; if not root: return [] queue = deque() ans = [] queue.append(root) while queue: node = queue.popleft() ans.append(node.val) if node.left: queue.append(node.left) if node.right: queue.append(node.right) return ans   Variant: level aware method  Leet-code: 102\n给你一个二叉树，请你返回其按 层序遍历 得到的节点值。 （即逐层地，从左到右访问所有节点）。 示例： 二叉树：[3,9,20,null,null,15,7], 3 / \\ 9 20 / \\ 15 7 返回其层次遍历结果： [ [3], [9,20], [15,7] ] 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/binary-tree-level-order-traversal 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 The key is to create a variable to record number of nodes in current level.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  from collections import deque class Solution(object): def levelOrder(self, root): \u0026#34;\u0026#34;\u0026#34; :type root: TreeNode :rtype: List[List[int]] \u0026#34;\u0026#34;\u0026#34; if not root: return [] queue = deque() ans = [] queue.append(root) while queue: temp = [] num_nodes_in_current_level = len(queue) while num_nodes_in_current_level \u0026gt; 0: node = queue.popleft() temp.append(node.val) if node.left: queue.append(node.left) if node.right: queue.append(node.right) num_nodes_in_current_level -= 1 # when reach this line, nodes in current level has been all explored ans.append(temp) return ans   ","date":1597536000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607967296,"objectID":"049f471b341c3c175c2c8174320c7554","permalink":"/resources/dsal/tree/tree_basic/","publishdate":"2020-08-16T00:00:00Z","relpermalink":"/resources/dsal/tree/tree_basic/","section":"resources","summary":"Traverse Algorithms Pre-order The pre-order traversal visit nodes in root - left - right order, where the the root appears in the first. recursion implementation 1 2 3 4 5","tags":null,"title":"Basics of tree data structure and algorithms","type":"docs"},{"authors":null,"categories":null,"content":"Smart Pointers - shared pointer   shared pointer  pass shared pointer to function  Pass by Reference and Pass by Pointer   differences between pass-by-reference and pass-by-pointer  ","date":1597104000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598900989,"objectID":"2b661429a92f9ae32adb59dc76e08fa7","permalink":"/resources/cpp_laopt/cpp/pointers/","publishdate":"2020-08-11T00:00:00Z","relpermalink":"/resources/cpp_laopt/cpp/pointers/","section":"resources","summary":"Smart Pointers - shared pointer   shared pointer  pass shared pointer to function  Pass by Reference and Pass by Pointer   differences between pass-by-reference and pass-by-pointer  ","tags":null,"title":"Pointers and Reference","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559407402,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":[],"categories":["shell"],"content":"Find files with specific patterns 1 2 3 4  # This command find files with name has `news20` in the current directory and all of its sub-directories. find . -name \u0026#39;*news20*\u0026#39; # This command find and delete files with name has `news20` in the current directory and all of its sub-directories. find . -name \u0026#39;*news20*\u0026#39; -delete   Show file size 1  ls -l --block-size=M   1 2  # show the disk usage of each directories under the path [dir] du -h --max-depth=1 [dir]   ","date":1596499200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596741242,"objectID":"f9ca43dbfa4b00c2a6c91ccdbb951369","permalink":"/post/bash-commands-collection/","publishdate":"2020-08-04T00:00:00Z","relpermalink":"/post/bash-commands-collection/","section":"post","summary":"Find files with specific patterns 1 2 3 4  # This command find files with name has `news20` in the current directory and all of its sub-directories. find . -name \u0026#39;*news20*\u0026#39; # This command find and delete files with name has `news20` in the current directory and all of its sub-directories.","tags":[],"title":"bash commands collection","type":"post"},{"authors":["Frank E. Curtis","Yutong Dai","Daniel P. Robinson"],"categories":null,"content":"","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596511776,"objectID":"2a4296a9f86561fc82385c8a924261a1","permalink":"/publication/farsagroup/","publishdate":"2020-07-01T00:00:00Z","relpermalink":"/publication/farsagroup/","section":"publication","summary":"We consider the problem of minimizing an objective function that is the sum of a convex function and a group sparsity-inducing regularizer. Problems that integrate such regularizers arise in modern machine learning applications, often for the purpose of obtaining models that are easier to interpret and that have higher predictive accuracy. We present a new method for solving such problems that utilize subspace acceleration, domain decomposition, and support identification. Our analysis shows, under common assumptions, that the iterate sequence generated by our framework is globally convergent, converges to an $\\epsilon$-approximate solution in at most $O(\\epsilon^{-(1+p)})$ (respectively, $O(\\epsilon^{-(2+p)})$) iterations for all $\\epsilon$ bounded above and large enough (respectively, all $\\epsilon$ bounded above) where $p  0$ is an algorithm parameter, and exhibits superlinear local convergence. Preliminary numerical results for the task of binary classification based on regularized logistic regression show that our approach is efficient and robust, with the ability to outperform a state-of-the-art method.","tags":["subspace acceleration","support identification","proximal gradient","second-order method"],"title":"A Subspace Acceleration Method for Minimization Involving a Group Sparsity-Inducing Regularizer","type":"publication"},{"authors":[],"categories":["python"],"content":"Show all submodules I need to import a particular function formulate from a file in the directory \u0026lt;path-to-the-package\u0026gt;/coinor/dippy/examples/milp/milp_func. It\u0026rsquo;s clear that I need to import it from the submodule coinor.dippy. But how to do it exactly? Use following commands, which list all submodules you can import.\n1 2 3 4 5 6 7  import pkgutil import coinor.dippy package=coinor.dippy for importer, modname, ispkg in pkgutil.walk_packages(path=package.__path__, prefix=package.__name__+\u0026#39;.\u0026#39;, onerror=lambda x: None): print(modname)   Relavant outputs are\n1 2 3 4 5  ..... coinor.dippy.examples.milp coinor.dippy.examples.milp.__main__ coinor.dippy.examples.milp.milp_func .....   Then I can simply use\n1  from coinor.dippy.examples.milp.milp_func import formulate   Using the right kernel for Jupyter Notebook 1 2 3 4 5 6 7 8 9 10  # create virtual env with python 3.7.7, whose name is cuppy conda create -n cuppy numpy scipy pandas notebook matplotlib python=3.7.7 # activate cuppy conda activate cuppy # I am using zsh, you may change to bash conda init zsh # activate virtual env cond activate cuppy # point this verison of Python to jupyter ipython kernel install --name \u0026#34;cuppy\u0026#34; --user   Running Jupyter Notebook from the remote server  Reference\n  set up jupyter notebook on login nodes.  set up jupyter notebook on computation nodes   On the server side:\n  Create following two functions in the .bashrc and reload it using source .bashrc\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  function Inode(){ # provide the computation node name; default is polyp2 local nodename=\u0026#34;${1:-polyp2}\u0026#34; echo \u0026#34;starting an interactive section at $nodename\u0026#34; # start an interactive session in the given node qsub -l nodes=$nodename:ppn=4 -l walltime=1:00:00 -l mem=10gb,vmem=10gb -I } function jpt(){ # provide the port; default is 1234 local port=\u0026#34;${1:-1234}\u0026#34; echo \u0026#34;open jupyter notebook at $(hostname):$port\u0026#34; # Fires-up a Jupyter notebook by supplying a specific port and ip jupyter notebook --no-browser --port=$port --ip=$(hostname) }     In the server side\u0026rsquo;s terminal, if\n If you want to start the jupyter notebook in the login node, just call jpt; If you want to start the jupyter notebook in the computation node, call Inode first and then when you are prompted to the computation node, then call jpt. For example, if the comutation node name is polyp3, then call Inode polyp3 and then call jpt 1234.    On the local side:\n  Create following two functions in the .bashrc and reload it using source .bashrc\n1 2 3 4 5 6 7 8 9 10 11 12  function jptt(){ local localport=\u0026#34;${1:-2234}\u0026#34; local servername=\u0026#34;${2:-polyp1}\u0026#34; local serverport=\u0026#34;${3:-1234}\u0026#34; # Forwards port $1 into port $3 and listens to it ssh -N -f -L localhost:$localport:$servername:$serverport yud319@polyps.ie.lehigh.edu } function stopjpt(){ local localport=\u0026#34;${1:-2234}\u0026#34; lsof -i tcp:$localport |awk \u0026#39;NR \u0026gt; 1 {print $2}\u0026#39; | xargs kill -9 echo \u0026#34;Kill port $localport\u0026#34; }     Call jptt on the local terminal, which will listen to the jupyter notebook host on the server.\n  In the browser, if the port on local side is set to 2234, the just type localhost::2234.\n  After finish the job, call stopjpt, which will free the local port.\n  copy and deepcopy caveats  slicing in the list: slicing operator and assigning in Python makes a shallow copy of the sliced list. But the following example can be confusing.  1 2 3 4 5 6 7 8 9 10 11 12 13 14  a = [1, 2, 3, 4] a_copy = a[:] a_copy[0] = 2 print(f\u0026#34;a: {a}\\na_copy:{a_copy}\u0026#34;) b = [[1,2], [3,4]] b_copy = b[:] b_copy[0][0] = 100 print(f\u0026#34;b: {b}\\nb_copy:{b_copy}\u0026#34;) c = [[1,2], [3,4]] c_copy = c[:] c_copy[0] = [-1, -1] print(f\u0026#34;c: {c}\\nc_copy:{c_copy}\u0026#34;)   output:\na: [1, 2, 3, 4] a_copy:[2, 2, 3, 4] b: [[100, 2], [3, 4]] b_copy:[[100, 2], [3, 4]] c: [[1, 2], [3, 4]] c_copy:[[-1, -1], [3, 4]]  explaination: the original list is copied to a new list object. Just all elements within the list are not copied, so if the list contains a mutable object (ints are not mutable) changing that object will change it in both the original and the copied list because both have a copy of the reference to the same object.\nMatplotlib caveats Sometimes your x-axis label contains underscore _. Since in the backend matplotlib shall use Tex to render texts, such special characters shall cause issues.\nIf you x-axis happens to be in a column of the pd.DataFrame, you can easily change the _ to - by using\n1  df_plot[\u0026#39;you_x_axis_label\u0026#39;].str.replace(\u0026#39;_\u0026#39;, \u0026#39;-\u0026#39;, regex=False)   ","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610906548,"objectID":"282d097486d35915811123a4ffe8089f","permalink":"/post/python-tricks-learned-from-projects/","publishdate":"2020-05-01T00:00:00Z","relpermalink":"/post/python-tricks-learned-from-projects/","section":"post","summary":"Show all submodules I need to import a particular function formulate from a file in the directory \u0026lt;path-to-the-package\u0026gt;/coinor/dippy/examples/milp/milp_func. It\u0026rsquo;s clear that I need to import it from the submodule coinor.dippy. But how to do it exactly?","tags":["python"],"title":"Python Tricks Learned From Projects","type":"post"},{"authors":null,"categories":["Optimization"],"content":" Some useful notes Farkas’s Lemma, Strong Duality and Criss-Cross Algorithm   ","date":1571356800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585430638,"objectID":"46aba06c97713885c14b80b492233241","permalink":"/post/lp/","publishdate":"2019-10-18T00:00:00Z","relpermalink":"/post/lp/","section":"post","summary":" Some useful notes Farkas’s Lemma, Strong Duality and Criss-Cross Algorithm   ","tags":["linear programming"],"title":"Introduction to Mathematical Programming","type":"post"},{"authors":[],"categories":["visualization"],"content":"中国传统计时单位 古时一天分12个时辰，采用地支作为时辰名称，分为\n'子', '丑', '寅', '卯' '辰', '巳', '午', '未' '申', '酉', '戌', '亥' 时辰的起点是午夜，即子初。\n点击下图色块便可查看时间对应。\n 附录\n 参考文献:    国学网  新浪博客 博主知书少年果麦麦  用于绘图的Python代码  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102  # using following code in jupyter notebook import plotly import plotly.graph_objs as go plotly.offline.init_notebook_mode(connected=True) colorPlate1 = [ \u0026#39;#ffb3a7\u0026#39;, \u0026#39;#ffc773\u0026#39;, \u0026#39;#ffa400\u0026#39;, \u0026#39;#c9dd22\u0026#39;, \u0026#39;#afdd22\u0026#39;, \u0026#39;#cca4e3\u0026#39;, \u0026#39;#b0a4e3\u0026#39;, \u0026#39;#ffc64b\u0026#39;, \u0026#39;#ffb61e\u0026#39;, \u0026#39;#758a99\u0026#39;, \u0026#39;#6b6882\u0026#39;, \u0026#39;#ffb3a7\u0026#39;, \u0026#39;#f47983\u0026#39;, \u0026#39;#ffc773\u0026#39;, \u0026#39;#ffa400\u0026#39;, \u0026#39;#c9dd22\u0026#39;, \u0026#39;#afdd22\u0026#39;, \u0026#39;#cca4e3\u0026#39;, \u0026#39;#b0a4e3\u0026#39;, \u0026#39;#ffc64b\u0026#39;, \u0026#39;#ffb61e\u0026#39;, \u0026#39;#758a99\u0026#39;, \u0026#39;#6b6882\u0026#39;, \u0026#39;#f47983\u0026#39; ] colorPlate2 = [\u0026#39;#ff4e20\u0026#39;, \u0026#39;#ff7500\u0026#39;, \u0026#39;#789262\u0026#39;, \u0026#39;#8d4bbb\u0026#39;, \u0026#39;#e9bb1d\u0026#39;,\u0026#39;#50616d\u0026#39;] * 2 theta_marker = [\u0026#34;{}:00\u0026#34;.format(i) for i in range(24)] timeStamp = [ \u0026#39;子正\u0026#39;, \u0026#39;丑初\u0026#39;, \u0026#39;丑正\u0026#39;, \u0026#39;寅初\u0026#39;, \u0026#39;寅正\u0026#39;, \u0026#39;卯初\u0026#39;, \u0026#39;卯正\u0026#39;, \u0026#39;辰初\u0026#39;, \u0026#39;辰正\u0026#39;, \u0026#39;巳初\u0026#39;, \u0026#39;巳正\u0026#39;, \u0026#39;午初\u0026#39;, \u0026#39;午正\u0026#39;, \u0026#39;未初\u0026#39;, \u0026#39;未正\u0026#39;, \u0026#39;申初\u0026#39;, \u0026#39;申正\u0026#39;, \u0026#39;酉初\u0026#39;, \u0026#39;酉正\u0026#39;, \u0026#39;戌初\u0026#39;, \u0026#39;戌正\u0026#39;, \u0026#39;亥初\u0026#39;, \u0026#39;亥正\u0026#39;, \u0026#39;子初\u0026#39; ] timeStampMain = [ \u0026#39;子, 名曰「困敦」\u0026lt;br\u0026gt;混沌万物之初萌，藏黄泉之下。\u0026lt;br\u0026gt; 子是兹的意思，这时候万物刚刚开始滋生和繁殖。\u0026#39;, \u0026#39;丑, 名曰「赤奋若」\u0026lt;br\u0026gt;气运奋迅而起，万物无不若其性。\u0026lt;br\u0026gt;形容万物继续萌发，系于生长。\u0026#39;, \u0026#39;寅, 名曰「摄提格」\u0026lt;br\u0026gt;万物承阳而起。\u0026lt;br\u0026gt;植物芽刚刚吐露，要吸收阳气生长，然后全部露出地面。\u0026#39;, \u0026#39;卯, 名曰「单阏」\u0026lt;br\u0026gt;阳气推万物而起. \u0026lt;br\u0026gt;卯，就是茂，茂盛的样子。这个时候，万物生长滋生繁茂。\u0026#39;, \u0026#39;辰, 名曰「执徐」\u0026lt;br\u0026gt;伏蛰之物，而敷舒出。\u0026lt;br\u0026gt;万物都震动而生长，草木伸舒，萌芽而出。\u0026#39;, \u0026#39;巳, 名曰「大荒落\u0026lt;br\u0026gt;万物炽盛而出，霍然落之。\u0026lt;br\u0026gt;万物到了这个时候，都全部长起来了，聚集在一起。炽盛而有光泽的样子。\u0026#39;, \u0026#39;午, 名曰「敦牂」\u0026lt;br\u0026gt;万物壮盛也。\u0026lt;br\u0026gt;万物都达到盛大壮茂，枝柯密布的状态。\u0026#39;, \u0026#39;未, 名曰「协洽」\u0026lt;br\u0026gt;阴阳和合，万物化生。\u0026lt;br\u0026gt;未，就是味的意思。当事物成熟的时候，都会发出气味。这时候阴气开始升起，万物稍微衰败。\u0026#39; , \u0026#39;申, 名曰「涒滩」\u0026lt;br\u0026gt;万物吐秀，倾垂也。\u0026lt;br\u0026gt;万物的身体都已成就，倾吐了最后的繁盛，引向衰败。\u0026#39;, \u0026#39;酉, 名曰「作噩」\u0026lt;br\u0026gt;万物皆芒枝起。 \u0026lt;br\u0026gt;万物衰老到极至而成熟。\u0026#39;, \u0026#39;戌, 名曰「阉茂」\u0026lt;br\u0026gt;万物皆蔽冒也。\u0026lt;br\u0026gt;戌，灭，杀的意思。意思是到了这时候，万物都已经衰灭了。\u0026#39;, \u0026#39;亥, 名曰「大渊献」\u0026lt;br\u0026gt;万物于天，深盖藏也。\u0026lt;br\u0026gt;亥，核的意思。万物都进入核阂里，意味着阴气劾杀了万物，等待下一个初萌。\u0026#39; ] def sectorChild(name, location, radius, fillcolor=\u0026#39;#ff4e20\u0026#39;): r = [0] * 24 r[location % 24] = radius r[(location + 1) % 24] = radius obj = go.Scatterpolar( name = name, r = r, theta = theta_marker, fill = \u0026#34;toself\u0026#34;, fillcolor = fillcolor, line = {\u0026#34;color\u0026#34;:\u0026#39;black\u0026#39;} ) return obj def sectorParent(name, location, radius, fillcolor=\u0026#39;black\u0026#39;): r = [0] * 24 if location == 0: r[0] = r[1] = r[23] = radius else: r[location % 24] = radius r[(location + 1) % 24] = radius r[(location + 2) % 24] = radius obj = go.Scatterpolar( name = name, r = r, theta = theta_marker, fill = \u0026#34;toself\u0026#34;, fillcolor = fillcolor, line = {\u0026#34;color\u0026#34;:\u0026#39;black\u0026#39;}, hoverinfo = \u0026#39;text\u0026#39;, hoverlabel = {\u0026#39;align\u0026#39;:\u0026#39;left\u0026#39;} ) return obj trace = [sectorChild(i, j, 5, k) for (i,j,k) in zip(timeStamp, range(24), colorPlate1)] trace += [sectorParent(timeStampMain[0], 0, 3, colorPlate2[0])] trace += [sectorParent(i, j, 3, k) for (i,j, k) in zip(timeStampMain[1:], range(1, 23, 2), colorPlate2[1:]) ] layout = go.Layout( polar = dict( radialaxis = dict( visible = False ), angularaxis = dict( direction = \u0026#34;clockwise\u0026#34;, visible = True, linewidth = 3 ) ), showlegend = False ) plotly.offline.iplot({ \u0026#34;data\u0026#34;: trace, \u0026#34;layout\u0026#34;: layout })   ","date":1562284800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566272759,"objectID":"a78143e43dd46b5640ab9af8fd0b0dd5","permalink":"/post/chinese-time/","publishdate":"2019-07-05T00:00:00Z","relpermalink":"/post/chinese-time/","section":"post","summary":"中国传统计时单位 古时一天分12个时辰，采用地支作为时辰名称，","tags":["visualization"],"title":"中国传统计时","type":"post"},{"authors":[],"categories":["optimization"],"content":"Problem Formulation There are commonly two ways of formulating the logistic regression problem, depending on the way we label the response variable $y$. Here we focus on the first formulation and defer the second formulation on the appendix.\nFirst Formulation:\nConsider restrict $y$ to {${-1,1}$}. Then we have $$ \\begin{aligned} \u0026amp;\\mathbb{P}(y=1|z)=\\sigma(z)=\\frac{1}{1 + e^{-z}}\\\n\u0026amp;\\mathbb{P}(y=-1|z)=\\sigma(z)=\\frac{1}{1 + e^z}, \\end{aligned} $$ which can be compactly written as $$ \\mathbb{P}(y|z)=\\sigma(zy). $$ If we consider the data $({x_i,y_i})_{i=1}^N$ and we want to use the Likelihood Principle to fit the Logistic Regression, then we would like to maximize the following loss function, $$ \\begin{aligned} \u0026amp; L(\\beta_0,\\beta) = \\prod_{i=1}^N \\mathbb{P}(y_i|z_i)\\\n\u0026amp; z_i =\\beta_0+\\beta^Tx_i. \\end{aligned} $$ If we use the first formulation, then it is equivalent to minimize the log-negative of $L(\\beta_0,\\beta)$, $$ \\begin{aligned} \\min_{\\beta_0,\\beta}l(\\beta_0,\\beta)=\\frac{1}{N}\\sum_{i=1}^N\\log(1+e^{-y_iz_i}). \\end{aligned} $$ From now on, for the sake of simplicity, we drop the intercept term $\\beta_0$.\nMotivating Example Consider two simulated datasets:\nDataset 1:\n   $x_1$ $x_2$ $y$     0.3 0.9 1   0.5 1.5 -1    Dataset 2:\n   $x_1$ $x_2$ $y$     2 1 1   -1 -1 -1    Some Analysis:\n The objective function $l(\\beta)$ is strictly convex by looking at its Hessian, which is positive defined. However, it is not strongly convex. For given Data set, the Hessian is upper bounded by $(\\sum_{i=1}^N|x_i|^2)I$ (see Appendix). The stepsize can be chosen as $\\alpha = \\frac{1}{\\sum_{i=1}^N|x_i|^2}$.  Applying the gradient descent with constant stepsize $\\frac{1}{L}$ on each dataset for 1000 steps, then we obtain the estimations as follows.\n   Dataset $\\beta_1$ $\\beta_2$     1 -0.12058225 -0.36174676   2 3.59370507 3.04825501    Also we plot out following figures to check the convergence. The top two figures describe the algorithm\u0026rsquo;s performance on the dataset 1 while the bottom two is for the dataset 2.\n   Fig1: Apply GD with the constant stepsize on two different datasets. The blue curves depicts how the norm of gradient at iterates change while the red curves show the change of the function value in each iteration.\n Analysis: why this happens? First, if we want to minimize $f(\\beta)=\\log(1 + \\exp(-\\beta))$ using gradient descent with constant stepsize $\\frac{1}{L}$, then we will facing following issues. Here we assume $\\beta \\in \\mathbb{R}$.\n The global minimal is not attainable, i.e., $+\\infty$, though we can have $\\nabla f(\\beta^k)\\rightarrow 0$, which means $\\beta \\rightarrow +\\infty$, hence the iterates diverge. Indeed, the ${f(\\beta^k)}$ converges to $f^*=0$ by as it monotonously decreasing and lower bounded by $0$. The worst-case iteration complexity is $\\mathcal{O}(\\frac{1}{k})$, indicating a sublinear convergence rate.  Now, let\u0026rsquo;s back to the example. The figure 2 shows that the first dataset and second dataset, which correspond to the non-separable and separable case respectively.\n   Fig2: (Left) First dataset. (Right) Second dataset. The fitted separating line is derived by $y=-\\frac{\\beta_1}{\\beta_2}x$.\n We also plot out the norm of iterates at each iteration in figure 3.\n   Fig3: The top figure shows the norm of iterates for the first dataset while the bottom one shows case for the second dataset.\n We can see that for non-separable case, the norm of iterates are bounded while the latter goes to infinity (if we increase the number of iterations).\nIn non-separable case, ${\\beta^k}$ seems to stay in \u0026ldquo;strongly convex\u0026rdquo; region while in separable case, ${\\beta^k}$ keeps approaching the flatten region, so you can easily say a sharp decreasing in convergence speed. The following observations can be verified by figure 4 (1-dimensional case) and figure 5 (2-dimensional case).\n   Fig4: (Left) Non-separable dataset ${(x_1=1, y_1=1), (x_2=2, y_2=-1)}$. The green dot line is $y=x^2$. The objective function (blue line) preserves the strong convexity in a certain range and the minimal stays in this range. The red point is the start point $x_0$. (Right). Separable dataset ${(x_1=1, y_1=1), (x_2=-1, y_2=-1)}$. Although the objective function is endowed with the strong convexity property in a certain range, however the global minimal is outside of this range.\n    Fig5: Dataset 1 is shown in the top 2 pictures with the right one zooming into a particular range. Dataset 2 is shown in the bottom pictures. The blue dots trace the progression of iterates.\n Questions  Why the separability would cause such a difference? From the Fig4 and Fig5, we know data as parameters can influence the shape of the objective function a lot. Given the data set, can we predict the behavior of the performance of gradient descent with constant stepsize, i.e., linear convergence rate or sublinear convergence rate? Can we extend our conclusion to higher dimension? In real world application, it\u0026rsquo;s likely that the data is semi-separable, i.e., most data points can be split into two groups with a few exceptions. How\u0026rsquo;s that influence the performance of the algorithm? Will second formulation (see below) also encounter the similar issue? My guess is yes.  Appendix Second Formulation of Logistic Regression\nConsider restrict $y$ to ${0,1}$. Then we have $$ \\begin{aligned} \u0026amp;\\mathbb{P}(y=1|z)=\\sigma(z)=\\frac{1}{1 + e^{-z}}\\\n\u0026amp;\\mathbb{P}(y=0|z)=\\sigma(z)=\\frac{1}{1 + e^z}, \\end{aligned} $$ which can be compactly written as $$ \\mathbb{P}(y|z)=\\sigma(z)^y(1-\\sigma(z))^{1-y}. $$\nIf we use the second formulation, then maximizing the likelihood is equivalent to $$ \\begin{aligned} \\min_{\\beta_0,\\beta}l(\\beta_0,\\beta)=\\frac{1}{N}\\sum_{i=1}^N[-y_iz_i+\\log(1+e^{z_i})]. \\end{aligned} $$\nDerivation of the gradient and Hessian of the loss function (first formualtion)\nConsider $f(\\beta)=\\log (1 + \\exp(-y\\beta^Tx)$, then we have\n$$ \\begin{aligned} \u0026amp;\\nabla f(\\beta) = \\frac{1}{1 + \\exp(y\\beta^Tx)}(-yx)\\\n\u0026amp;\\nabla^2 f(\\beta) = (yx)\\frac{\\exp(y\\beta^Tx)}{1 + \\exp(y\\beta^Tx)}(yx^T), \\end{aligned} $$ which implies $$ \\begin{aligned} \u0026amp; \\nabla l(\\beta)=\\frac{1}{N}\\sum_{i=1}^N \\frac{1}{1 + \\exp(y_i\\beta^Tx_i)}(-y_ix_i)\\\n\u0026amp; \\nabla^2 l(\\beta)=\\frac{1}{N}\\sum_{i=1}^N(y_ix_i)\\frac{\\exp(y\\beta^Tx_i)}{(1 + \\exp(y\\beta^Tx_i))^2}(y_ix_i^T)=\\frac{1}{N}XDX^T, \\end{aligned} $$ where $X=[x_1,\\cdots,x_n]$ , $D=\\text{diag}({y_1^2\\sigma_1(1-\\sigma_1),\\cdots,y_n^2\\sigma_n(1-\\sigma_n)})$ , and $\\sigma_i =\\frac{\\exp(y\\beta^Tx_i)}{1 + \\exp(y\\beta^Tx_i)} $.\nReference:\n  Lecture notes 9 and 10 presented on this course website.\n  The code for generating graphs can be found in my git repo.\n  ","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596511776,"objectID":"473ae1c2728e1a3326fc148defe204ad","permalink":"/post/gradient-descent-in-logistic-regression/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/post/gradient-descent-in-logistic-regression/","section":"post","summary":"Problem Formulation There are commonly two ways of formulating the logistic regression problem, depending on the way we label the response variable $y$. Here we focus on the first formulation and defer the second formulation on the appendix.","tags":[],"title":"Gradient Descent in Logistic Regression","type":"post"},{"authors":["Yutong Dai","Yang Weng"],"categories":null,"content":"","date":1554076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596505925,"objectID":"f934a9b2b0fdb05ac23f1c7f653ed912","permalink":"/publication/psum/","publishdate":"2019-04-01T00:00:00Z","relpermalink":"/publication/psum/","section":"publication","summary":"In this paper, we propose a synchronous parallel block coordinate descent algorithm(PSUM) for minimizing a composite function, which consists of a smooth convex function plus a non-smooth but separable convex function. Due to the generalization of our method, some existing synchronous parallel algorithms can be considered as special cases. To tackle high dimensional problems, we further develop a randomized variant, which randomly update some blocks of coordinates at each round of computation. Both proposed parallel algorithms are proven to have sub-linear convergence rate under rather mild assumptions. The numerical experiments on solving the large scale regularized logistic regression with $l_1$ norm penalty show that the implementation is quite efficient. We conclude with explanation on the observed experimental results and discussion on the potential improvements.","tags":["Convex Optimization","Block Cooridinate Descent"],"title":"Synchronous Parallel Block Coordinate Descent Method for Nonsmooth Convex Function Minimization","type":"publication"},{"authors":[],"categories":[],"content":"Welcome to Slides  Academic\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\n1 2 3  porridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;)    Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n1 2 3 4  {{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}   Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n1 2 3  {{\u0026lt; slide background-image=\u0026#34;/img/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}}    Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n1 2 3 4 5  .reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }    Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559407402,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":["Statistics"],"content":"  1 Point Anomaly Detection - Grubbs' test 2 Collective Anomaly Detection 2.1 Anomaly in timeseries - Seasonal Hybrid ESD algorithm 2.2 Distance-based Anomaly Detection 2.2.1 Global Anomaly - Largest Distance 2.2.2 Local Anomaly - LOF   3 Isolation Forest 3.1 Isolation Score    1 Point Anomaly Detection - Grubbs' test Grubbs' test1 is commonly used technique to detect an outlier in univariate problem, where normality assumption is required. It can be formualted as either one-side testing problem or two-sided testing problem.\nThe hypothesis test is defined as\n\\[H_0: \\text{There are no outlier in the data set} \\quad H_1: \\text{There is exactly one outlier in the data set}.\\] For two-sided testing, it tries to determine whether the observation with the largest absolute deviation is an outlier, where the test statistic is defined as\n\\[ G = \\frac{\\max_i |X_i - \\bar X|}{s}, \\] where the \\(\\bar X\\) is the sample mean and \\(s\\) is the sample deviation.\nLet's look at one simulated example.\nset.seed(123) simulated_data \u0026lt;- rnorm(100, 0, 1) simulated_data_with_outliers \u0026lt;- c(simulated_data, c(3.5, -3.7)) # normality check shapiro.test(simulated_data_with_outliers) ## ## Shapiro-Wilk normality test ## ## data: simulated_data_with_outliers ## W = 0.9804, p-value = 0.1344 Shapiro-Wilk normality test impiles the data is normally distributed. Now, let's performe the grubbs' test.\nlibrary(outliers) grubbs.test(simulated_data_with_outliers, two.sided = TRUE) ## ## Grubbs test for one outlier ## ## data: simulated_data_with_outliers ## G = 3.65380, U = 0.86651, p-value = 0.01626 ## alternative hypothesis: lowest value -3.7 is an outlier The test result detecs the lowest value as an outlier.\nLet's remove the -3.7 and performe the test again.\ngrubbs.test(head(simulated_data_with_outliers,101), two.sided = TRUE) ## ## Grubbs test for one outlier ## ## data: head(simulated_data_with_outliers, 101) ## G = 3.48190, U = 0.87755, p-value = 0.03378 ## alternative hypothesis: highest value 3.5 is an outlier Finally, let's remove two outliers altogether.\ngrubbs.test(head(simulated_data_with_outliers,100), two.sided = TRUE) ## ## Grubbs test for one outlier ## ## data: head(simulated_data_with_outliers, 100) ## G = 2.62880, U = 0.92949, p-value = 0.7584 ## alternative hypothesis: lowest value -2.30916887564081 is an outlier This impiles there are no outliers.\nGrubbs' test is useful for identify the outliers of a small amount one at a time, but not suitable to detect a group of outliers.\n 2 Collective Anomaly Detection 2.1 Anomaly in timeseries - Seasonal Hybrid ESD algorithm # devtools::install_github(\u0026quot;twitter/AnomalyDetection\u0026quot;) library(AnomalyDetection) river \u0026lt;- read.csv(\u0026quot;https://raw.githubusercontent.com/Rothdyt/personal-blog/master/static/post/dataset/river.csv\u0026quot;) results \u0026lt;- AnomalyDetectionVec(river$nitrate, period=12, direction = \u0026#39;both\u0026#39;, plot = T) results$plot  2.2 Distance-based Anomaly Detection 2.2.1 Global Anomaly - Largest Distance Intuitively, the larger distance the more likely the point would be an outlier.\nlibrary(FNN) ## Warning: package \u0026#39;FNN\u0026#39; was built under R version 3.4.4 furniture \u0026lt;- read.csv(\u0026quot;https://raw.githubusercontent.com/Rothdyt/personal-blog/master/static/post/dataset/furniture.csv\u0026quot;) furniture_scaled \u0026lt;- data.frame(Height = scale(furniture$Height), Width = scale(furniture$Width)) furniture_knn \u0026lt;- get.knn(furniture_scaled, k = 5) furniture_scaled$score_knn \u0026lt;- rowMeans(furniture_knn$nn.dist) largest_idx \u0026lt;- which.max(furniture_scaled$score_knn) plot(furniture_scaled$Height, furniture_scaled$Width, cex=sqrt(furniture_scaled$score_knn), pch=20) points(furniture_scaled$Height[largest_idx], furniture_scaled$Width[largest_idx], col=\u0026quot;red\u0026quot;, pch=20)  2.2.2 Local Anomaly - LOF kNN is useful for finding global anomalies, but is less able to surface local outliers.\nLOF is a ratio of densities:\n LOF \u0026gt; 1 more likely to be anomalous LOF ≤ 1 less likely to be anomalous Large LOF values indicate more isolated points  library(dbscan) furniture_lof \u0026lt;- furniture[,2:3] furniture_lof$score_lof \u0026lt;- lof(scale(furniture_lof), k=5) largest_idx \u0026lt;- which.max(furniture_lof$score_lof) plot(furniture_lof$Height, furniture_lof$Width, cex=sqrt(furniture_lof$score_lof), pch=20) points(furniture_lof$Height[largest_idx], furniture_lof$Width[largest_idx], col=\u0026quot;red\u0026quot;, pch=20) It's clear that, lof successfuly detects the local outlier.\n   3 Isolation Forest  Isolation Forest is built on the basis of decision trees; To grow a decision tree, at each node, a feature and a corresponding cutoff value are randomly selected; Intuitively, outliers are less frequent than regular observations and are different from them in terms of values, so outliers should be identified closer to the root of the tree with fewer splits. We use isolation score to characterize this.  3.1 Isolation Score We need some quatity to define the isolation score2\n Path Length: \\(h(x)\\) of a point \\(x\\) is measured by the number of edges \\(x\\) traverses an iTree from the root node until the traversal is terminated at an external node. Normalizing constant \\[c(n) = 2H(n − 1) − (2(n − 1)/n)\\], where \\(n\\) is the number of samples to grow a tree and \\(H(i)\\) is the harmonic number and it can be estimated by \\(ln(i) + 0.5772156649\\) (Euler’s constant).  The isolation score \\(s\\) of an sample \\(x\\) is defined as \\[s(x,n)= 2^{-\\frac{E(h(x))}{c(n)}},\\] where the \\(E()\\) is the expectation of \\(h(x)\\).\n Interpreting the isolation score:\n Scores between 0 and 1 Scores near 1 indicate anomalies (small path length)\n  # devtools::install_github(\u0026quot;Zelazny7/isofor\u0026quot;) library(isofor) furniture \u0026lt;- read.csv(\u0026quot;https://raw.githubusercontent.com/Rothdyt/personal-blog/master/static/post/dataset/furniture.csv\u0026quot;) furniture \u0026lt;- data.frame(Height = furniture$Height, Width = furniture$Width) scores \u0026lt;- matrix(nrow=dim(furniture)[1]) for (ntree in c(100, 200, 500)){ furniture_tree \u0026lt;- iForest(furniture, nt = ntree, phi=50) scores \u0026lt;- cbind(scores, predict(furniture_tree, furniture)) } plot(scores[,3], scores[,4], xlab = \u0026quot;200 tress\u0026quot;, ylab=\u0026quot;500 tress\u0026quot;) abline(a=0,b=1) This graph is used to assess wheter the number of trees is enough for the isolation score to converge. From the graph above, we know that 200 tress are enough for us to identify the anomalies.\nlibrary(lattice) furniture_forest \u0026lt;- iForest(furniture, nt = 200, phi=50) h_seq \u0026lt;- seq(min(furniture$Height), max(furniture$Height), length.out = 20) w_seq \u0026lt;- seq(min(furniture$Width), max(furniture$Width), length.out = 20) furniture_grid \u0026lt;- expand.grid(Width = w_seq, Height = h_seq) furniture_grid$score \u0026lt;- predict(furniture_forest, furniture_grid) contourplot(score ~ Height + Width, data = furniture_grid,region = TRUE) This contour graph used to identify the anomaly regions.\n   https://en.wikipedia.org/wiki/Grubbs%27_test_for_outliers↩\n Zhihua Zhou et al. https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf↩\n   ","date":1546560000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596511776,"objectID":"0f9c92b28639dcbc1da16b2bc8ac9897","permalink":"/post/anomaly-detection/","publishdate":"2019-01-04T00:00:00Z","relpermalink":"/post/anomaly-detection/","section":"post","summary":"1 Point Anomaly Detection - Grubbs' test 2 Collective Anomaly Detection 2.1 Anomaly in timeseries - Seasonal Hybrid ESD algorithm 2.2 Distance-based Anomaly Detection 2.2.1 Global Anomaly - Largest Distance 2.","tags":["data-analysis"],"title":"Anomaly Detection","type":"post"},{"authors":null,"categories":["Python-Programming"],"content":"  Prepare a fitted random forest Find the path to desired terminal node Collect Paths in the random forest Summarize the decison region   Prepare a fitted random forest import random import pandas as pd from sklearn.ensemble.forest import RandomForestRegressor from sklearn import tree data = pd.DataFrame({\u0026quot;Y\u0026quot;:[1,5,3,4,3,4,2], \u0026quot;X_1\u0026quot;:[\u0026quot;red\u0026quot;, \u0026quot;blue\u0026quot;, \u0026quot;blue\u0026quot;, \u0026quot;red\u0026quot;,\u0026quot;red\u0026quot;,\u0026quot;blue\u0026quot;, \u0026quot;red\u0026quot;], \u0026quot;X_2\u0026quot;:[18.4, 7.5, 9.3, 3.7, 5.2, 3.2, 5.2]}) data = pd.get_dummies(data) X = data.drop([\u0026quot;Y\u0026quot;], axis=1) y = data[\u0026quot;Y\u0026quot;] rf = RandomForestRegressor(n_estimators = 10, random_state = 1234) rf.fit(X, y) output:\nRandomForestRegressor(bootstrap=True, criterion=\u0026#39;mse\u0026#39;, max_depth=None, max_features=\u0026#39;auto\u0026#39;, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1, oob_score=False, random_state=1234, verbose=0, warm_start=False)  Find the path to desired terminal node import pydotplus import re def return_node_path_to_max_prediction(onetree, verbose=True): \u0026quot;\u0026quot;\u0026quot; @input: a tree from the sklearn randomforest @output: the node path to maxmium terminal node [[split_node_1], [split_node_2], ...] [splite_node_1] = [var_index, cutoff, direction] \u0026quot;\u0026quot;\u0026quot; if verbose: print(\u0026quot;Generating Tree Graph, it may take a while...\u0026quot;) dot_data = tree.export_graphviz(onetree, out_file = None, filled = True, rounded = True, special_characters = True) graph = pydotplus.graph_from_dot_data(dot_data) graph_ = {} for edge in graph.get_edge_list(): graph_[edge.get_source()] = edge.get_destination() # find all terminal node terminal_node = {} non_decimal = re.compile(r\u0026#39;[^\\d.]+\u0026#39;) for node in graph.get_node_list(): if node.get_name() not in graph_: if node.get_name() not in [\u0026quot;node\u0026quot;, \u0026quot;edge\u0026quot;]: value = node.get_label() value = re.sub(r\u0026#39;.*v\u0026#39;, \u0026#39;v\u0026#39;, value) terminal_node[node.get_name()] = float(non_decimal.sub(\u0026#39;\u0026#39;, value)) # find the path down to the terminal with maximum predition value flag = True destination = max(terminal_node, key=terminal_node.get) edge_list = graph.get_edge_list() node_list = graph.get_node_list() split_node = [] while flag: myedge = [edge for edge in edge_list if edge.get_destination() == destination][0] if int(myedge.get_destination()) - int(myedge.get_source()) \u0026gt; 1: direction = \u0026quot;Right\u0026quot; else: direction = \u0026quot;Left\u0026quot; mynode = [node for node in node_list if node.get_name() == myedge.get_source()][0] var_val = re.findall(r\u0026quot;[-+]?\\d*\\.\\d+|\\d+\u0026quot;, mynode.get_label())[:2] # record the growing path: # var_val[0]: Index of variable participating in splitting # var_val[1]: cutoff point of the splitting # direction: If Right, means greater than var_val[1]; # If Left, means no greater than var_val[1] split_node.append([int(var_val[0]),float(var_val[1]),direction]) if verbose: print(myedge.get_destination() + \u0026quot;\u0026lt;-\u0026quot; + myedge.get_source() + \u0026quot;: Split at Variable X\u0026quot; + var_val[0] + \u0026quot;; The cutoff is \u0026quot; + var_val[1] + \u0026quot;; Turn \u0026quot; + direction) destination = myedge.get_source() if destination == \u0026quot;0\u0026quot;: flag = False return [*reversed(split_node)] Test:\nreturn_node_path_to_max_prediction(rf[1], verbose=True) Outputs:\nGenerating Tree Graph, it may take a while... 3\u0026lt;-1: Split at Variable X0; The cutoff is 5.6; Turn Right 1\u0026lt;-0: Split at Variable X0; The cutoff is 12.95; Turn Left From the output above, we know the path from the root to the desired terminal node is :\nRoot[X0(\u0026lt;= 12.95)] -\u0026gt; X0 (\u0026gt;=5.6) -\u0026gt; Terminal Node\n Collect Paths in the random forest def collect_path(rf, verbose=True): n_tree = len(rf) result = [] for i in range(n_tree): if verbose: print(\u0026quot;Construct the %s tree graph out of %s trees\u0026quot; %(i+1, n_tree)) result.append(return_node_path_to_max_prediction(rf.estimators_[i], verbose=False)) return result Test:\nresult = collect_path(rf) print(result) Outputs:\nConstruct the 1 tree graph out of 10 trees Construct the 2 tree graph out of 10 trees Construct the 3 tree graph out of 10 trees Construct the 4 tree graph out of 10 trees Construct the 5 tree graph out of 10 trees Construct the 6 tree graph out of 10 trees Construct the 7 tree graph out of 10 trees Construct the 8 tree graph out of 10 trees Construct the 9 tree graph out of 10 trees Construct the 10 tree graph out of 10 trees [[[0, 4.2, \u0026#39;Left\u0026#39;]], [[0, 12.95, \u0026#39;Left\u0026#39;], [0, 5.6, \u0026#39;Right\u0026#39;]], [[1, 0.5, \u0026#39;Right\u0026#39;], [0, 8.4, \u0026#39;Left\u0026#39;]], [[0, 13.85, \u0026#39;Left\u0026#39;], [0, 8.4, \u0026#39;Left\u0026#39;], [1, 0.5, \u0026#39;Right\u0026#39;]], [[0, 8.4, \u0026#39;Left\u0026#39;], [0, 6.35, \u0026#39;Right\u0026#39;]], [[0, 12.95, \u0026#39;Left\u0026#39;], [0, 5.6, \u0026#39;Right\u0026#39;]], [[2, 0.5, \u0026#39;Left\u0026#39;], [0, 5.35, \u0026#39;Right\u0026#39;]], [[1, 0.5, \u0026#39;Right\u0026#39;], [0, 5.35, \u0026#39;Right\u0026#39;]], [[0, 13.85, \u0026#39;Left\u0026#39;], [1, 0.5, \u0026#39;Right\u0026#39;], [0, 8.4, \u0026#39;Left\u0026#39;], [0, 5.35, \u0026#39;Right\u0026#39;]], [[0, 13.85, \u0026#39;Left\u0026#39;], [0, 6.35, \u0026#39;Right\u0026#39;], [0, 8.4, \u0026#39;Left\u0026#39;]]]  Summarize the decison region def summarize_region(result, features): decision_region = {k: [[] for _ in range(2)] for k in features} for i in range(len(result)): for j in range(len(result[i])): if result[i][j][2] == \u0026quot;Left\u0026quot;: decision_region[features[result[i][j][0]]][0].append(result[i][j][1]) else: decision_region[features[result[i][j][0]]][1].append(result[i][j][1]) decision_region_ = {} for k in features: try: upper_bound = min(decision_region[k][0]) except ValueError: upper_bound = \u0026quot;Unknown\u0026quot; try: lower_bound = max(decision_region[k][1]) except ValueError: lower_bound = \u0026quot;Unknown\u0026quot; decision_region_[k] = [lower_bound, upper_bound] value_to_remove = [\u0026#39;Unknown\u0026#39;, \u0026#39;Unknown\u0026#39;] decision_region_ = {key: value for key, value in decision_region_.items() if value != value_to_remove} value_to_remove = [0.5, 0.5] decision_region_ = {key: value for key, value in decision_region_.items() if value != value_to_remove} return (decision_region_) Test:\nfeatures = X.columns summarize_region(result, features) Outputs:\n{\u0026#39;X_1_blue\u0026#39;: [0.5, \u0026#39;Unknown\u0026#39;], \u0026#39;X_1_red\u0026#39;: [\u0026#39;Unknown\u0026#39;, 0.5], \u0026#39;X_2\u0026#39;: [6.35, 4.2]} From the output above, we know that the decision region:\n{blue} * [6.35, 4.2] But it seems that the region [6.35, 4.2] is not reasonable due to the poorly generated data. But it may happens in some situations, which may require us to come up with new ways to ensemble these terminal nodes.\n ","date":1530921600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559407402,"objectID":"0093d29b100375be265b5486a11eaca1","permalink":"/post/decision-tree-how-to-find-the-path-from-the-root-to-the-desired-terminal-node/","publishdate":"2018-07-07T00:00:00Z","relpermalink":"/post/decision-tree-how-to-find-the-path-from-the-root-to-the-desired-terminal-node/","section":"post","summary":"Find terminal nodes in each tree of the built random forest that give the largest prediction. Then find paths from root to these selected terminal nodes and ensemble them to derive a decision region.","tags":["RandomForest"],"title":"Decision Tree: How to find the path from the root to the desired terminal node","type":"post"},{"authors":null,"categories":null,"content":"In this project, we\n Develope data products to help Airbnb hosts to determine listing prices using Sparse Regression and RandomForest Researched how amenities and geolocation in uence listing prices Designed a User Interface for customers to gain insight into Airbnb rental markets in Boston  The Video Presentation and Rshiny App Demo are also provided.\n","date":1512882000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546015024,"objectID":"690845e8dc7a3b2b3563f360194fbc75","permalink":"/project/boston-housing/","publishdate":"2017-12-10T00:00:00-05:00","relpermalink":"/project/boston-housing/","section":"project","summary":"Develope data products to help Airbnb hosts to determine listing prices.","tags":["Data Analysis"],"title":"Real Estate Market Data Analysis","type":"project"},{"authors":null,"categories":null,"content":"This is the deep learning course final project trying to reporduce the results reported in the paper, Show and Tell: A Neural Image Caption Generator.\nThe model is trained on the MS coco2014 dataset. Our final result looks like\nFor code, UI, and report please click here.\n","date":1512882000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559407402,"objectID":"217bfb70762bb4746b8027e79602a247","permalink":"/project/show-and-tell/","publishdate":"2017-12-10T00:00:00-05:00","relpermalink":"/project/show-and-tell/","section":"project","summary":"Feed in an image, AI will generate the caption for you!","tags":["Deep Learning","CNN","LSTM"],"title":"Show and Tell: A Neural Image Caption Generator","type":"project"},{"authors":null,"categories":null,"content":"This is the statistical computing course final project, trying to understand, reporduce and extend some results reported in the paper, Variational Inference: A Review for Statisticians.\nThree datasets are used here, simulated data, old faithful and imageCLEF.\nOur final result looks like\n Simulated data    old faithful   imageclef\n  For code and report please click here.\n","date":1512882000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559407402,"objectID":"ef4fca63f9151ea900f34782ac9bfb47","permalink":"/project/variational-inference/","publishdate":"2017-12-10T00:00:00-05:00","relpermalink":"/project/variational-inference/","section":"project","summary":"Clustering under the variation inference framework.","tags":["Data Analysis"],"title":"Variational Gaussian Mixtures","type":"project"},{"authors":null,"categories":["optimization"],"content":"  Problem description Notations Assumption Algorithm  Convergence Analysis Powell's example R codes for numerical experiments   We mainly focus on the convergence of Block coordinate decent with exact minimization, whose block update strategy employs Gauss-Seidel manner. And then use Powell's example to see what will happen if some conditions are not met.\n Reference: 1. Dimitri .P Bertsekas, Nonlinear Programming 2ed 2. Powell ,1973, ON SEARCH DIRECTIONS FOR MINIMIZATION ALGORITHMS\n Problem description Notations We want to solve the problem:\n\\[\\mathop{min}_{x\\in X}\\quad f(x)\\]\nwhere X is a Cartesian product of closed convex sets $X_1,...,X_m:X=_{i=1}^n X_i $\nWe assume that \\(X_i\\) is a closed convex subset of \\(R^{n_i}\\) and \\(n=\\sum_{i=1}^m n_i\\). The vector is partitioned into \\(m\\) block(s) such that \\(x_i \\in X^{n_i}\\).\nWe denote \\(\\nabla_i f\\) as the gradient of \\(f\\) with respect to component \\(x_i\\).\n Assumption We shall assume that for every \\(x\\in X\\) and \\(i=1,2,...m\\) the optimization problem\n\\[\\mathop{min}_{\\xi\\in X_i}\\quad f(x_1,...,x_{i-1},\\xi,x_{i+1,....,x_m})\\]\nhas at least one solution.\n Algorithm The Gauss-Seidel method, generates the next iterate \\(x^{k+1}=(x^{k+1}_1,...,x^{k+1}_m)\\), given the current the iterate \\(x^{k}=(x^{k}_1,...,x^{k}_m)\\), according to the iteration\n\\[x^{k+1}_i=\\mathop{argmin}_{\\xi\\in X_i}\\quad f(x_1^{k+1},...,x^{k+1}_{i-1},\\xi,x^k_{i+1},...,x_m^k)\\]\n  Convergence Analysis Theorem Suppose that \\(f\\) is continuously differentiable over the set \\(X\\) defined as above. Furthermore, suppose that for each \\(i\\) and \\(x\\in X\\),\n\\[f(x_1,...,x_{i-1},\\xi,x_{i+1,....,x_m})\\]\nviewed as a function of \\(\\xi\\), attains a unique minimum \\(\\bar x_i\\) over \\(X_i\\) and is monotonically non-increasing in the interval from \\(x_i\\) to \\(\\bar \\xi\\). Let \\(\\{x_k\\}\\) be the sequence generated by the block coordinate method with Gauss-Seidel manner. Then, every limit point of \\(\\{x_k\\}\\) is a stationary point.\nPROOF\nLet\n\\[z_i^k=(x_1^{k+1},...,x_i^{k+1},x_{i+1}^k,...,x_m^k)\\]\nBy the nature of this algorithm, for all \\(k\\geq 0\\), we have following inequality\n\\[f(x^k)\\geq f(z_1^k)\\geq f(z_2^k)\\geq ...\\geq f(z_{m-1}^k)\\geq f(x^{k+1}) \\quad (*)\\]\nSince \\(\\{x_k\\}in X\\), we can assume \\(\\{x^{k_j}\\}\\) is the subsequence that converges to \\(\\bar x=(\\bar x_1,..,\\bar x_m)\\).\nNow we want prove that \\(\\bar x\\) is the stationary point of \\(f\\).\nFrom (*), we know that\n\\[f(z_1^{k_j})\\leq f(x_1,x_2^{k_j},..., x_m^{k_j})\\qquad \\forall x_1\\in X_1\\]\nLet \\(j\\rightarrow +\\infty\\), we derive\n\\[f(\\bar x)\\leq f(x_1,\\bar x_2,..., \\bar x_m)\\overset \\Delta = h(x_1)\\qquad \\forall x_1\\in X_1\\]\nwhich implies that \\(\\bar x_i\\) is the minima of \\(h(x_1)\\) on \\(X_1\\). Using the optimality over a convex set, we conclude that\n\\[h\u0026#39;(\\bar x_1)(\\bar x_1 -x_1)\\geq 0 \\Leftrightarrow (x_1-\\bar x_1)^T\\nabla_1f(\\bar x_1)\\geq 0\\qquad x_1\\in X_1\\]\nAt this stage, if we can prove that \\(\\{z_1^{k_j}\\}\\) converges to \\(\\bar x\\), we can show that\n\\[ (x_2-\\bar x_2)^T\\nabla_2 f(\\bar x_2)\\geq 0\\qquad x_2\\in X_2\\], since\n\\[f(z_1^{k_j})=f(x_1^{k_j+1},x_2^{k_j},x_3^{k_j},...,x_m^{k_j})\\leq f(x_1^{k_j+1},x_2,x_3^{k_j},...,x_m^{k_j})\\qquad x_2\\in X_2\\]\nLet \\(j\\rightarrow +\\infty\\), we derive\n\\[f(\\bar x)\\leq f(\\bar x_1,\\bar x_2,\\bar x_3,..., \\bar x_m)\\qquad \\forall x_2\\in X_2\\]\nand\n\\[(x_2-\\bar x_2)^T\\nabla_2f(\\bar x_2)\\geq 0\\qquad x_2\\in X_2\\]\n(Note: Although \\(x_1^{k_j+1}\\) may not in the sequence \\(\\{x_1^{k_t}\\}_{t\\geq 1}\\) ,which convergences to \\(\\bar x_1\\), but \\(\\{z_1^{k_j}\\}\\) converges to \\(\\bar x\\), so its component \\(x_1^{k_j+1}\\) converges to \\(\\bar x_1\\)).\nFurthermore, if we prove that for \\(i=1,2,...,m-1\\),\\(\\{z_i^{k_j}\\}\\) convergences to \\(\\bar x\\), then we have\n\\[(x_i-\\bar x_i)^T\\nabla_i\\;f(\\bar x_i)\\geq 0\\qquad x_i\\in X_i\\]\nAnd thus \\(\\bar x\\) is a stationary point, since \\((x-\\bar x)^T\\nabla f(\\bar x)\\geq 0\\)\nBy far, it remains to prove that \\(\\{z_i^{k_j}\\}\\quad,\\forall i\\) convergence to \\(\\bar x\\). First,we try to prove that \\(\\{z_1^{k_1}\\}\\) convergence to \\(\\bar x\\).\nAssume the contrary that \\(r^{k_j}=\\vert \\vert z_1^{k_j}-x^{k_j}\\vert \\vert\\) doesn't convergence to 0. Let \\(s_1^{k_j}=(z_1^{k_j}-x^{k_j})/r^{k_j}\\). Thus, \\(z_1^{k_j}=x^{k_j}+r^{k_j}s_1^{k_j}\\) , \\(\\vert \\vert r_{k_j}\\vert \\vert =1\\) and \\(s_1^{k_j}\\) differs from 0 only along the first block-component. Since \\(\\{s_1^{k_j}\\}\\) belong to a compact set and therefore without loss of generality, we assume \\(s_1^{k_j}\\) convergences to \\(\\bar s_1\\).\nSince \\(r^{k_j}\u0026gt;0\\),we can find a \\(\\epsilon\\in (0,1)\\), such that \\(x^{k_j}+\\epsilon s_1^{k_j}\\) lies on the segment joining \\(x^{k_j}\\) and \\(x^{k_j}+s_1^{k_j}=z_1^{k_j}\\). Using the non-increasing property of \\(f\\),we derive,\n\\[f(z_1^{k_j})\\leq f(x^{k_j}+\\epsilon s_1^{k_j}) \\leq f(x^{k_j})\\]\nAgain, using (*), we conclude\n\\[f(x^{k_{j+1}})\\leq f(z_1^{k_j})\\leq f(x^{k_j}+\\epsilon s_1^{k_j}) \\leq f(x^{k_j})\\]\nLet \\(j\\rightarrow +\\infty\\), we derive \\(f(\\bar x)=f(\\bar x+\\epsilon \\bar s_1)\\), which contradicts the hypothesis that \\(f\\) is uniquely minimized when viewed as a function of the first block component. This contradiction establishes that \\(\\{z_1^{k_1}\\}\\) convergence to \\(\\bar x\\).\nSimilarly, let \\(r_t^{k_j}=\\vert \\vert z_t^{k_j}-z_{t-1}^{k_j}\\vert \\vert\\) for \\(t=2,3,...,m-1\\) and using the same technique shown above, we finally prove that \\(\\{z_i^{k_j}\\},\\quad \\forall i\\).\n Powell's example In ON SEARCH DIRECTIONS FOR MINIMIZATION ALGORITHMS, Power actually gives three examples that sequences generated by the algorithm discussed above do not convergence to stationary points once some hypothesis are not met.\n The first example is straightforward, However, the remarkable properties of this example can be destroyed by making a small perturbation to the starting vector \\(x^0\\).\n The second example is not sensitive to either small changes in the initial data or to small errors introduced during the iterative process, for example computer rounding errors.\n The third example suggests that a function that is infinitely differentiable that also causes an endless loop in the iterative minimization method.\n  We here only presents the first example. Consider the following function\n\\[f(x,y,z)=-(xy+yz+zx)+(x-1)_+^2+(-x-1)_+^2+(y-1)_+^2+(-y-1)_+^2+(z-1)_+^2+(-z-1)_+^2\\]\nwhere\n\\[(x-c)_+^2=\\begin{cases}0,x-c\u0026lt; 0\\\\ (x-c)^2,x-c\\geq 0\\end{cases}\\]\nGiven the starting point \\(x_0=(-1-e,1+\\frac{1}{2}e,-1-\\frac{1}{4}e)\\) and use block coordinate decent algorithm,and we update the variable in a manner of \\(x\\rightarrow y\\rightarrow z\\rightarrow x ...\\) with\n\\[x_{k+1}^{**}\\leftarrow \\text{sign}(y_k+z_k)[1+\\frac{1}{2}\\vert y_k+z_k\\vert ]\\]\n\\[y_{k+1}^{**}\\leftarrow \\text{sign}(x_{k+1}+z_k)[1+\\frac{1}{2}\\vert x_{k+1}+z_k\\vert ]\\]\n\\[z_{k+1}^{**}\\leftarrow \\text{sign}(x_{k+1}+y_{k+1})[1+\\frac{1}{2}\\vert x_{k+1}+y_{k+1}\\vert ]\\]\nWe here present the first six steps of this case\n  cycle/totall iteration x y z    1/1 1+\\(\\frac{1}{8}e\\) 1+$e $ -1-\\(\\frac{1}{4}e\\)  1/2 1+\\(\\frac{1}{8}e\\) -1-\\(\\frac{1}{16}e\\) -1-\\(\\frac{1}{4}e\\)  1/3 1+\\(\\frac{1}{8}e\\) -1-\\(\\frac{1}{16}e\\) 1+\\(\\frac{1}{32}e\\)  2/4 -1-\\(\\frac{1}{64}e\\) -1-\\(\\frac{1}{16}e\\) 1+\\(\\frac{1}{32}e\\)  2/5 -1-\\(\\frac{1}{64}e\\) 1+\\(\\frac{1}{128}e\\) 1+\\(\\frac{1}{32}e\\)  2/6 -1-\\(\\frac{1}{64}e\\) 1+\\(\\frac{1}{128}e\\) -1-\\(\\frac{1}{256}e\\)  3/7 1+\\(\\frac{1}{512}e\\) 1+\\(\\frac{1}{128}e\\) -1-\\(\\frac{1}{256}e\\)  ... ... ... ...    This result implies that the sequence obtained by this algorithm can not converge to one single point since \\(x-coordinate\\) change its sign as the even cycle and odd cycle alternate. Situations are similar for \\(y-coordinate\\) and \\(z-coordinate\\).\nBut \\(\\{x_k\\}\\) has six sub-sequences which convergence to (1,1,-1), (1,-1,-1), (1,-1,1), (-1,-1,1),(-1,-1,1),(-1,1,1),(-1,1,-1) respectively.\n Remark\nA hint to derive the update formula:\n\\[x\\leftarrow \\text{sign}(y+z)[1+\\frac{1}{2}(y+z)]\\]\nIndeed, derivates of \\((x-1)_+^2\\) and \\((-x-1)_+^2\\) are as follows respecively\n\\[\\frac{d(x-1)_+^2}{dx}=\\begin{cases}2(x-1),x\\geq 1\\\\0,x\u0026lt;1\\end{cases}\\quad \\frac{d(-x-1)_+^2}{dx}=\\begin{cases}2(-x-1),x\\leq -1\\\\0,x\u0026gt;-1\\end{cases} \\]\nSo for the univariate optimization problem, setting the derivate of \\(g(x)=f(x,y,z)\\) to zero, we conclude\n\\[\\frac{\\partial f(x,y,x)}{\\partial x}=0\\Rightarrow \\begin{cases}x\\geq 1: x=1+\\frac{1}{2}(y+z)\\\\-1\u0026lt; x\u0026lt;1: -(y+z)=0\\\\x\\leq -1:x=-1+\\frac{1}{2}(y+z) \\end{cases}\\]\n The gradient of \\(f(x,y,z)\\) on this cyclic path, is \\(\\nabla f(x,y,z)=(-y-z,-x-z,-x-y)\\) and \\(\\vert \\vert \\nabla f(x,y,z)\\vert \\vert _1=2\\)\n This example is unstable with respect to small perturbations. Small changes in the starting point \\(x_0=(-1-e,1+\\frac{1}{2}e,-1-\\frac{1}{4}e)\\) or smal errors in the numbers that are computed during the calculation will destroy the cyclic behavior.\nIt's s clear the choice of perturbations \\(e\\) plays a key role. Say, \\(x_0=(-1-e_1,1+e_2,-1-e_3)\\) and we have \\(e_k=\\frac{1}{2}(e_{k-2}- e_{k-1})\\)\n  cycle/totall iteration x y z    1/1 1+\\(e_4\\) 1+\\(e_2\\) -1-\\(e_3\\)  1/2 1+\\(e_4\\) -1-\\(e_5\\) -1-\\(e_3\\)  1/3 1+\\(e_4\\) -1-\\(e_5\\) 1+\\(e_6\\)  2/4 -1-\\(e_7\\) -1-\\(e_5\\) 1+\\(e_6\\)  2/5 -1-\\(e_7\\) 1+\\(e_8\\) 1+\\(e_6\\)  2/6 -1-\\(e_7\\) 1+\\(e_8\\) -1-\\(e_9\\)  ... ... ... ...    To preserve the cyclic behavior , we have to make sure that \\(e_{k-2}\u0026gt;e_{k-1}\\)\nAnd in practice, when we do some numerical tests, we shall find that, this theoretically-existed endless loop actual breaks down due to the rounding errors. A brief illustration is given below. In this experiment, loop ends at the 52 steps.\n As\n\\[\\frac{\\partial f(x,y,x)}{\\partial x}=0\\Rightarrow \\begin{cases}x\\geq 1: x=1+\\frac{1}{2}(y+z)\\\\-1\u0026lt; x\u0026lt;1: -(y+z)=0\\\\x\\leq -1:x=-1+\\frac{1}{2}(y+z) \\end{cases}\\]\nsuggests that, when \\(-1\u0026lt;x\u0026lt;1\\), the choice of \\(x\\) is arbitrary and we set \\(x^*=0\\) in the case above. So the uniqueness requirement is violated. It turns out that the six vertices are even not the stationary points.\nFor example, at point \\(\\bar x=(1,1,-1)\\), \\(\\nabla f(\\bar x)=(0,0,-2)\\) and for any ponit \\(x\\) in the unit cubic \\((x-\\bar x)^T\\nabla f(\\bar x)\\leq 0\\). Say, \\(x=(0.9,0.9,-0.9)\\), \\((x-\\bar x)^T\\nabla f(\\bar x)=-0.2\u0026lt;0\\)\nActually, as in the proof of Theorem, we prove that \\(\\{z_1^{k_j}\\}\\) converges to \\(\\bar x\\), where \\(\\bar x\\) is the limit point of \\(\\{x^{k_j}\\}\\). But in this example, the limit point of \\(\\{z_1^{k_j}\\}\\) is (1,1,-1) while the limit point of \\(\\{x^{k_j}\\}\\) is either (-1,1,-1) or (1,-1,1). So the requirement of uniqueness is not met.\n   R codes for numerical experiments #################### ### Function for test ### #################### PowellE1\u0026lt;-function(xstart,cycles,fig=T){ #######function part ############## UpdateCycle\u0026lt;-function(x){ Sign\u0026lt;-function(x){ if (x\u0026gt;0){ return(1) }else{ if (x\u0026lt;0){ return(-1) }else{ return(0) } } } x.new\u0026lt;-c() x.new[1]\u0026lt;-Sign(x[2]+x[3])*(1+0.5*abs(x[2]+x[3])) x.new[2]\u0026lt;-Sign(x.new[1]+x[3])*(1+0.5*abs(x.new[1]+x[3])) x.new[3]\u0026lt;-Sign(x.new[1]+x.new[2])*(1+0.5*abs(x.new[1]+x.new[2])) cycle\u0026lt;-matrix(c(x.new[1],x[2],x[3],x.new[1],x.new[2],x[3],x.new[1],x.new[2],x.new[3]), ncol=3,byrow=T) return(cycle) } fpowell\u0026lt;-function(x){ PostivePart\u0026lt;-function(x){ ifelse(x\u0026gt;=0,x,0) } fval\u0026lt;-(-(x[1]*x[2]+x[2]*x[3]+x[1]*x[3]))+ PostivePart(x[1]-1)^2+PostivePart(-x[1]-1)^2+ PostivePart(x[2]-1)^2+PostivePart(-x[2]-1)^2+ PostivePart(x[3]-1)^2+PostivePart(-x[3]-1)^2 return(fval) } ############ operation part ################ x.store\u0026lt;-matrix(ncol=3,nrow=cycles*3+1) x.store[1,]\u0026lt;-xstart for (i in seq_len(cycles)){ x.store[(3*i-1):(3*i+1),]\u0026lt;-UpdateCycle(x.store[3*i-2,]) } x.store\u0026lt;-x.store[-1,] fval\u0026lt;-rep(0,cycles*3) for(i in seq_len(cycles*3)){ fval[i]\u0026lt;-fpowell(x.store[i,]) } fval\u0026lt;-as.matrix(fval) if (fig==T){ plot(fval,ylim=c(min(fval)-1,max(fval)+1),type=\u0026quot;l\u0026quot;,xlab=\u0026quot;Iterations\u0026quot;,ylab = \u0026quot;F value\u0026quot;) } r\u0026lt;-list() r$x.iterate\u0026lt;-x.store r$fval\u0026lt;-fval return(r) } ################## #### Test 1 ######## ################## perturb\u0026lt;-0.5 xstart\u0026lt;-c(-1-perturb,1+0.5*perturb,-1-0.25*perturb) cycles\u0026lt;-20 r\u0026lt;-PowellE1(xstart,cycles,fig=T) ################## #### Test 2 ######## ################## perturb\u0026lt;-0.5 xstart\u0026lt;-c(-1-perturb,1+0.5*perturb,-1-0.25*perturb) cycles\u0026lt;-20 r\u0026lt;-PowellE1(xstart,cycles,fig=T) ################## #### Test 3 ######## ################## xstart\u0026lt;-c(3,2,1) cycles\u0026lt;-100 r\u0026lt;-PowellE1(xstart,cycles,fig=T)  ","date":1479340800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596511776,"objectID":"8412461298db1d9651b4bc3fba2d8fb8","permalink":"/post/convergence-analysis-for-block-coordinate-descent-algorithm-and-powells-examples/","publishdate":"2016-11-17T00:00:00Z","relpermalink":"/post/convergence-analysis-for-block-coordinate-descent-algorithm-and-powells-examples/","section":"post","summary":"Convergence analysis of Block coordinate decent with exact minimization.","tags":["Powell-Example"],"title":"Convergence Analysis for Block Coordinate Decent Algorithm and Powell's Examples","type":"post"}]